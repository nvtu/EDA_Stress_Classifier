{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 90,
   "source": [
    "from dataset_loader import *\n",
    "from classifiers import *\n",
    "from result_utils import *\n",
    "from sklearn.cluster import DBSCAN, KMeans\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier, GradientBoostingClassifier\n",
    "from classifiers import *\n",
    "from result_utils import *"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "source": [
    "dataset_name = 'WESAD_WRIST'\n",
    "dataset_name = 'AffectiveROAD'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "source": [
    "WINDOW_SIZE = 60\n",
    "WINDOW_SHIFT = 1"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "source": [
    "SCORING = 'balanced_accuracy'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "source": [
    "ds_loader = DatasetLoader(dataset_name, WINDOW_SIZE = WINDOW_SIZE, WINDOW_SHIFT = WINDOW_SHIFT)\n",
    "result_helper = ResultUtils(dataset_name, WINDOW_SIZE = WINDOW_SIZE, WINDOW_SHIFT = WINDOW_SHIFT)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "source": [
    "detection_strategy = 'random_forest'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "source": [
    "X = ds_loader.dataset\n",
    "y = ds_loader.ground_truth\n",
    "groups = ds_loader.groups"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "source": [
    "logo = LeaveOneGroupOut()\n",
    "new_X = np.array([])\n",
    "new_y = np.array([])\n",
    "new_groups = np.array([])\n",
    "for train_index, test_index in logo.split(X, y, groups):\n",
    "    _X, _y = X[test_index], y[test_index]\n",
    "    model = KMeans(n_clusters = 3, random_state = 0)\n",
    "    model.fit(_X)\n",
    "    scores = []\n",
    "    for index in list(set(model.labels_)):\n",
    "        indices = np.where(model.labels_ == index)[0]\n",
    "        __y = _y[indices]\n",
    "        scores.append(np.median(__y))\n",
    "    sorted_indices = np.argsort(scores)\n",
    "    print(scores, np.argsort(scores))\n",
    "    for label, index in enumerate(sorted_indices):\n",
    "        if label == 1: continue\n",
    "        indices = np.where(model.labels_ == index)[0]\n",
    "        _y[indices] = min(label, 1)\n",
    "        new_y = np.concatenate((new_y, _y[indices]))\n",
    "        if new_X.shape[0] == 0:\n",
    "            new_X = _X[indices]\n",
    "        else:\n",
    "            new_X = np.concatenate((new_X, _X[indices]))\n",
    "        new_groups = np.concatenate((new_groups, groups[test_index][indices]))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[0.2711110738689664, 0.6776262865250516, 0.0] [2 0 1]\n",
      "[0.5503061727260281, 0.0, 0.0] [1 2 0]\n",
      "[0.0, 0.5398219773779167, 0.8067961343988724] [0 1 2]\n",
      "[0.6214357301699539, 0.57722047239123, 0.0] [2 1 0]\n",
      "[0.46801309504151334, 0.41825492273625536, 0.0] [2 1 0]\n",
      "[0.23621440713858732, 0.0, 0.5503121185725278] [1 0 2]\n",
      "[0.6130810394333873, 0.0, 0.0] [1 2 0]\n",
      "[0.5548419709809188, 0.8138550836845277, 0.8194364198348578] [0 1 2]\n",
      "[0.849613576183839, 0.0, 0.7408680594919594] [1 2 0]\n",
      "[0.6521027256847292, 0.0, 0.0] [1 2 0]\n",
      "[0.0, 0.8596233378590816, 0.5515039419238178] [0 2 1]\n",
      "[0.5577855370899276, 0.49241996924738063, 0.0] [2 1 0]\n",
      "[0.41137500000000005, 0.0, 0.4940616666666667] [1 0 2]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "source": [
    "print(set(new_groups))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'Drv13', 'Drv6', 'Drv5', 'Drv1', 'Drv12', 'Drv4', 'Drv11', 'Drv2', 'Drv3', 'Drv10', 'Drv8', 'Drv7', 'Drv9'}\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "source": [
    "strategies = ['random_forest']\n",
    "SCORING = 'balanced_accuracy'\n",
    "for detection_strategy in strategies:\n",
    "    detector_type = 'General'\n",
    "    print(f'--- RUNNING {detector_type} {detection_strategy} ---')\n",
    "    clf = BinaryClassifier(new_X, new_y, detection_strategy, logo_validation = True, groups = new_groups, scoring = SCORING)\n",
    "    # clf = BinaryClassifier(ds_loader.hrv_dataset, ds_loader.ground_truth, detection_strategy, logo_validation = True, groups = ds_loader.groups, scoring = SCORING)\n",
    "    # clf = BinaryClassifier(ds_loader.eda_dataset, ds_loader.ground_truth, detection_strategy, logo_validation = True, groups = ds_loader.groups, scoring = SCORING)\n",
    "    results = clf.exec_classifier() # Build classifier and return prediction results\n",
    "    print('------------------------------------------------------')\n",
    "\n",
    "    # # %%\n",
    "    # # Save results\n",
    "    result_helper = ResultUtils(dataset_name, WINDOW_SHIFT = WINDOW_SHIFT, WINDOW_SIZE = WINDOW_SIZE)\n",
    "    result_helper.dump_result_to_csv(results, detection_strategy, detector_type, physiological_signal_type = '')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "--- RUNNING General random_forest ---\n",
      "Counter({0.0: 16571, 1.0: 13214})\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "1it [00:08,  8.09s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "--- Test Group Drv1 BA Score: 0.36384976525821594 --- Train BA Score 1.0 ---\n",
      "Counter({0.0: 15428, 1.0: 12043})\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2it [00:15,  7.90s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "--- Test Group Drv10 BA Score: 0.7697039525074207 --- Train BA Score 1.0 ---\n",
      "Counter({0.0: 14909, 1.0: 12358})\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "3it [00:22,  7.73s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "--- Test Group Drv11 BA Score: 0.4332411245878209 --- Train BA Score 1.0 ---\n",
      "Counter({0.0: 15851, 1.0: 11807})\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "4it [00:30,  7.71s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "--- Test Group Drv12 BA Score: 0.39421813403416556 --- Train BA Score 1.0 ---\n",
      "Counter({0.0: 16263, 1.0: 12275})\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "4it [00:33,  8.42s/it]\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-102-3b63aa4769b6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m# clf = BinaryClassifier(ds_loader.hrv_dataset, ds_loader.ground_truth, detection_strategy, logo_validation = True, groups = ds_loader.groups, scoring = SCORING)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m# clf = BinaryClassifier(ds_loader.eda_dataset, ds_loader.ground_truth, detection_strategy, logo_validation = True, groups = ds_loader.groups, scoring = SCORING)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexec_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Build classifier and return prediction results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'------------------------------------------------------'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PhD_Work/StressDetection/EDA_Stress_Classifier/classifiers.py\u001b[0m in \u001b[0;36mexec_classifier\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    197\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_validator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogo_validation\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleave_one_group_out_validator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PhD_Work/StressDetection/EDA_Stress_Classifier/classifiers.py\u001b[0m in \u001b[0;36mleave_one_group_out_validator\u001b[0;34m(self, method)\u001b[0m\n\u001b[1;32m    168\u001b[0m             \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__transform_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Feature scaling if possible\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m             \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m             \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m             \u001b[0;31m# Run prediction on test set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m             \u001b[0my_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/nmduy/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    384\u001b[0m             \u001b[0;31m# parallel_backend contexts set at a higher level,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m             \u001b[0;31m# since correctness does not rely on using threads.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 386\u001b[0;31m             trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n\u001b[0m\u001b[1;32m    387\u001b[0m                              \u001b[0;34m**\u001b[0m\u001b[0m_joblib_parallel_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'threads'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m                 delayed(_parallel_build_trees)(\n",
      "\u001b[0;32m/home/nmduy/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1042\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1043\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1044\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/nmduy/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    919\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 921\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    922\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/nmduy/anaconda3/lib/python3.8/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    763\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 765\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    766\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/nmduy/anaconda3/lib/python3.8/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    760\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 762\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    763\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/nmduy/anaconda3/lib/python3.8/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    556\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 558\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    559\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/nmduy/anaconda3/lib/python3.8/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    300\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# logo = LeaveOneGroupOut()\n",
    "# test_groups = []\n",
    "# balanced_accs = []\n",
    "# for train_index, test_index in tqdm(logo.split(X, y, groups)):\n",
    "#     X_train, y_train, X_test, y_test = X[train_index], y[train_index], X[test_index], y[test_index]\n",
    "#     print(f'--- RUNNING MODEL CLUSTERING {groups[test_index][0]} ---')\n",
    "#     scaler = StandardScaler()\n",
    "#     scaler.fit(X_train)\n",
    "#     X_train = scaler.transform(X_train)\n",
    "#     X_test = scaler.transform(X_test)\n",
    "#     # cluster_model = KMeans(n_clusters = 3, random_state = 0, n_jobs = -1, max_iter = 10000).fit(X_train)\n",
    "#     print(f'--- TRAINING MODEL {groups[test_index][0]} ---')\n",
    "        # estimators = [('rf', RandomForestClassifier(n_estimators = 1000, random_state = 0, n_jobs = 8, max_features='sqrt',\n",
    "        #                                 oob_score=True, bootstrap=True, class_weight = 'balanced', )),    \n",
    "        #     ('svm', SVC(C = 10, random_state = 0, class_weight = 'balanced')),\n",
    "        #     ('mlp', MLPClassifier(random_state = 0, early_stopping = True, max_iter = 1000, activation = 'logistic'))\n",
    "        # ]\n",
    " \n",
    "    # _X_train = cluster_model.transform(X_train)\n",
    "    # _X_test = cluster_model.transform(X_test)\n",
    "    # y_preds = vclf.predict(X_test)\n",
    "    # clf = RandomForestClassifier(n_estimators = 1000, random_state = 0, n_jobs = 8, max_features='sqrt',\n",
    "                                    # oob_score=True, bootstrap=True, class_weight = 'balanced', )\n",
    "    # pipeline = Pipeline([('scaler', StandardScaler()), ('pca', PCA(n_components = 8)), \n",
    "    #         ('kmeans', KMeans(n_clusters = 3, random_state = 0, n_jobs = -1, max_iter = 10000)),\n",
    "    #         ('clf', RandomForestClassifier(n_estimators = 1000, random_state = 0, n_jobs = 8, max_features='sqrt',\n",
    "    #                                 oob_score=True, bootstrap=True, class_weight = 'balanced', ))\n",
    "    #     ])\n",
    "    # pipeline.fit(X_train)\n",
    "    # y_preds = pipeline.predict(X_test)\n",
    "    # test_labels = pipeline.predict(X_test)\n",
    "    # y_preds = y_test.copy()\n",
    "    # for i in list(set(pipeline['kmeans'].labels_)):\n",
    "    #     # clf = RandomForestClassifier(n_estimators = 1000, random_state = 0, n_jobs = 8, max_features='sqrt',\n",
    "    #                                 # oob_score=True, bootstrap=True, class_weight = 'balanced', )    \n",
    "    #     estimators = [('rf', RandomForestClassifier(n_estimators = 1000, random_state = 0, n_jobs = 8, max_features='sqrt',\n",
    "    #                                     oob_score=True, bootstrap=True, class_weight = 'balanced', )),    \n",
    "    #         ('svm', SVC(C = 10, random_state = 0, class_weight = 'balanced')),\n",
    "    #         ('mlp', MLPClassifier(random_state = 0, early_stopping = True, max_iter = 1000, activation = 'logistic'))\n",
    "    #     ]\n",
    "    #     clf = VotingClassifier(estimators = estimators, n_jobs=-1, verbose = True)\n",
    "    #     clf.fit(X_train, y_train)\n",
    "    #     # clf = SVC(C = 10, random_state = 0, class_weight = 'balanced')\n",
    "    #     indices = np.where(pipeline['kmeans'].labels_ == i)[0]\n",
    "    #     _indices = np.where(test_labels == i)[0]\n",
    "    #     if len(_indices) == 0:\n",
    "    #         continue\n",
    "    #     _X = scaler.fit_transform(X_train[indices])\n",
    "    #     _X_test = scaler.transform(X_test[_indices])\n",
    "    #     _y = y_train[indices]\n",
    "    #     clf.fit(_X, _y)\n",
    "    #     pred = clf.predict(_X_test)\n",
    "    #     y_preds[_indices] = pred\n",
    "    #     # estimators.append((f'rf_{i+1}', clf))\n",
    "    \n",
    "    acc = balanced_accuracy_score(y_test, y_preds)\n",
    "    print(f'Test {groups[test_index[0]]}: {acc}')\n",
    "    # break\n",
    "    # clf = BinaryClassifier(X_train, y_train, detection_strategy, scoring = SCORING)\n",
    "    # acc = clf.train_and_infer(X_test, y_test)\n",
    "    # balanced_accs.append(acc)\n",
    "    # test_groups.append(groups[test_index][0])\n",
    "    # break\n",
    "# results = { 'groups': test_groups, 'balanced_accuracy_score': balanced_accs }"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "IndentationError",
     "evalue": "unexpected indent (<ipython-input-83-fc6c02821b70>, line 56)",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-83-fc6c02821b70>\"\u001b[0;36m, line \u001b[0;32m56\u001b[0m\n\u001b[0;31m    acc = balanced_accuracy_score(y_test, y_preds)\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.3",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.3 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "a1d5b9100ccb4936a513a4c2e96581413c43726381ca42ceaddfd68a024f20b1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}