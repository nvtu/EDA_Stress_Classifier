{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import configparser\n",
    "import os\n",
    "import os.path as osp\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import pickle\n",
    "from typing import List, Dict\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize data paths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get dataset path\n",
    "config_path = osp.join(osp.abspath(os.pardir), 'config.ini')\n",
    "parser = configparser.ConfigParser()\n",
    "parser.read(config_path)\n",
    "wesad_dataset_path = parser['DATA_PATH']['wesad_dataset_path']\n",
    "wesad_chest_dataset_path = osp.join(wesad_dataset_path, 'WESAD_CHEST')\n",
    "wesad_wrist_dataset_path = osp.join(wesad_dataset_path, 'WESAD_WRIST')\n",
    "\n",
    "# List of user ids\n",
    "user_ids = os.listdir(wesad_chest_dataset_path)\n",
    "\n",
    "# Objective ground-truth file path\n",
    "ground_truth_path = osp.join(wesad_dataset_path, 'WESAD-Ground-Truth.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform dataset into a predefined format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>INSTANCE</th>\n      <th>LABEL</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>S10_baseline_1.csv</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>S10_amusement_2.csv</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>S10_meditation_3.csv</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>S10_stress_4.csv</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>S10_meditation_5.csv</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": [
       "               INSTANCE  LABEL\n",
       "0    S10_baseline_1.csv      0\n",
       "1   S10_amusement_2.csv      0\n",
       "2  S10_meditation_3.csv      0\n",
       "3      S10_stress_4.csv      1\n",
       "4  S10_meditation_5.csv      0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load ground-truth\n",
    "ground_truth = pd.read_csv(ground_truth_path)\n",
    "ground_truth.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define function to load data, map data ground-truth, and finally check the integrity of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(dataset_path: str, user_ids: List[str]) -> Dict[str, Dict[str, List[float]]]:\n",
    "    eda = defaultdict(dict)\n",
    "    for user_id in tqdm(user_ids):\n",
    "        user_data_path = osp.join(dataset_path, user_id)\n",
    "        file_names = sorted(os.listdir(user_data_path), key = lambda file_name: file_name.split('_')[-1]) # Sort the files as order by its name index\n",
    "        for file_name in file_names:\n",
    "            data_file_path = osp.join(user_data_path, file_name)\n",
    "            eda_signal = [line.rstrip() for line in open(data_file_path, 'r').readlines()][1:] # Load eda data and remove the first row of its as it is the header\n",
    "            eda_signal = list(map(float, eda_signal))\n",
    "            task_id = file_name # Task id is also its file name --> This is important to retrieve the ground-truth\n",
    "            eda[user_id][task_id] = eda_signal\n",
    "    return eda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_data_groundtruth(dataset: Dict[str, Dict[str, List[float]]], ground_truth: pd.DataFrame) -> Dict[str, Dict[str, List[int]]]:\n",
    "    ground_truth = ground_truth.set_index('INSTANCE') # Set index of the ground-truth file to task_id for retrieval\n",
    "    gt = defaultdict(dict)\n",
    "    for user_id, data in tqdm(dataset.items()):\n",
    "        for task_id, eda_signal in data.items():\n",
    "            task_ground_truth = ground_truth.loc[task_id].values # Get task ground-truth\n",
    "            len_eda_signal = len(eda_signal)\n",
    "            gt[user_id][task_id] = task_ground_truth.tolist() * len_eda_signal # Duplicate ground-truth to label each eda signal\n",
    "    return gt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_assertion(dataset: Dict[str, Dict[str, List[float]]], ground_truth: Dict[str, Dict[str, List[int]]]):\n",
    "    for user_id, data in tqdm(dataset.items()):\n",
    "        for task_id, eda_signal in data.items():\n",
    "            len_eda_signal = len(eda_signal)\n",
    "            len_gt = len(ground_truth[user_id][task_id])\n",
    "            # Assert the length of the ground-truth == the length of eda signal\n",
    "            if len_eda_signal != len_gt:\n",
    "                print(user_id, task_id, 'Length not equal')\n",
    "                print(len_eda_signal, len_gt)\n",
    "            # Assert if the signal has missing values?\n",
    "            if any(elem is None for elem in eda_signal):\n",
    "                print(user_id, task_id, 'Has None value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dump_dataset_pickle(eda: Dict[str, Dict[str, List[float]]], ground_truth: Dict[str, Dict[str, List[int]]], file_path: str):\n",
    "    data = { 'eda': eda, 'ground_truth': ground_truth }\n",
    "    pickle.dump(data, open(file_path, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load WESAD_CHEST data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0%|          | 0/15 [00:00<?, ?it/s]Load EDA_CHEST data...\n",
      "100%|██████████| 15/15 [00:28<00:00,  1.89s/it]\n",
      "100%|██████████| 15/15 [00:00<00:00, 116.84it/s]Map ground-truth to each data signal\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load eda data and its ground-truth\n",
    "print(\"Load EDA_CHEST data...\")\n",
    "eda_wesad_chest = load_dataset(wesad_chest_dataset_path, user_ids)\n",
    "print(\"Map ground-truth to each data signal\")\n",
    "gt_wesad_chest = map_data_groundtruth(eda_wesad_chest, ground_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:01<00:00,  9.33it/s]\n"
     ]
    }
   ],
   "source": [
    "# Assert that the data is correct\n",
    "data_assertion(eda_wesad_chest, gt_wesad_chest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save dataset\n",
    "output_file_path = osp.join(wesad_dataset_path, 'wesad_chest_dataset.pkl')\n",
    "dump_dataset_pickle(eda_wesad_chest, gt_wesad_chest, output_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load WESAD_WRIST data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13%|█▎        | 2/15 [00:00<00:00, 17.91it/s]Load EDA_WRIST data...\n",
      "100%|██████████| 15/15 [00:00<00:00, 17.35it/s]\n",
      "100%|██████████| 15/15 [00:00<00:00, 1156.90it/s]Map ground-truth to each data signal\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load eda data and its ground-truth\n",
    "print(\"Load EDA_WRIST data...\")\n",
    "eda_wesad_wrist = load_dataset(wesad_wrist_dataset_path, user_ids)\n",
    "print(\"Map ground-truth to each data signal\")\n",
    "gt_wesad_wrist = map_data_groundtruth(eda_wesad_wrist, ground_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:00<00:00, 939.89it/s]\n"
     ]
    }
   ],
   "source": [
    "# Assert that the data is correct\n",
    "data_assertion(eda_wesad_wrist, gt_wesad_wrist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save dataset\n",
    "output_file_path = osp.join(wesad_dataset_path, 'wesad_wrist_dataset.pkl')\n",
    "dump_dataset_pickle(eda_wesad_wrist, gt_wesad_wrist, output_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}