{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import os\n",
    "import os.path as osp\n",
    "import numpy as np\n",
    "import configparser\n",
    "from classifiers import BinaryClassifier\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "from tqdm import tqdm"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load eda statistical features and ground-truth from datasets"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "def get_dataset_folder_path(dataset_name: str) -> str:\n",
    "    # Read dataset path from config.ini file\n",
    "    config_path = osp.join(os.getcwd(), 'config.ini')\n",
    "    parser = configparser.ConfigParser()\n",
    "    parser.read(config_path)\n",
    "    dataset_folder_path = None\n",
    "    if dataset_name == 'AffectiveROAD':\n",
    "        dataset_folder_path = parser['DATA_PATH']['affectiveROAD_dataset_path']\n",
    "    elif dataset_name in ['WESAD_CHEST', 'WESAD_WRIST', 'RESAMPLED_WESAD_CHEST']:\n",
    "        dataset_folder_path = parser['DATA_PATH']['wesad_dataset_path']\n",
    "    elif dataset_name == 'DCU_NVT_EXP1':\n",
    "        dataset_folder_path = parser['DATA_PATH']['dcu_nvt_dataset_path']\n",
    "    return dataset_folder_path"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "def load_dataset(dataset_name: str):\n",
    "    dataset = None\n",
    "    ground_truth = None\n",
    "    # Initialize dataset folder path\n",
    "    dataset_folder_path = get_dataset_folder_path(dataset_name)\n",
    "    # Initialize dataset file path\n",
    "    dataset_file_path = osp.join(dataset_folder_path, f'{dataset_name}_heart_stats_feats_1_60.npy')\n",
    "    # Initialize ground-truth file path\n",
    "    ground_truth_file_path = osp.join(dataset_folder_path, f'{dataset_name}_ground_truth_1_60.npy')\n",
    "    # Initialize group file path\n",
    "    group_file_path = osp.join(dataset_folder_path, f'{dataset_name}_groups_1_60.npy')\n",
    "\n",
    "\n",
    "    # Load dataset, ground-truth, and groups\n",
    "    dataset = np.load(dataset_file_path) # Load dataset\n",
    "    ground_truth = np.load(ground_truth_file_path) # Load corresponding ground-truth\n",
    "    groups = np.load(group_file_path) # Load corresponding user_id labels\n",
    "    print(set(ground_truth))\n",
    "\n",
    "    dataset[np.isnan(dataset)] = 0\n",
    "    # Filtering preprocess if dataset name is AffectiveROAD\n",
    "    if dataset_name == 'AffectiveROAD':\n",
    "        indices = np.where(ground_truth >= 0)[0]\n",
    "        dataset = dataset[indices]\n",
    "        groups = groups[indices]\n",
    "        ground_truth = ground_truth[indices]\n",
    "        \n",
    "    return dataset, ground_truth, groups"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Define functions to get output folder path and save results"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "def get_output_folder_path(dataset_name: str) -> str:\n",
    "    config_path = osp.join(os.getcwd(), 'config.ini')\n",
    "    parser = configparser.ConfigParser()\n",
    "    parser.read(config_path)\n",
    "    # Get output_folder_path for a specific dataset\n",
    "    output_folder_path = osp.join(parser['DATA_PATH']['result_path'], dataset_name)\n",
    "    # Create the output folder if it does not exist\n",
    "    if not osp.exists(output_folder_path):\n",
    "        os.makedirs(output_folder_path)\n",
    "    return output_folder_path"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "def dump_result_to_csv(results, dataset_name: str, detection_strategy: str, detector_type: str):\n",
    "    output_folder_path = osp.join(get_output_folder_path(dataset_name), detector_type)\n",
    "    # Create the folder if it does not exist\n",
    "    if not osp.exists(output_folder_path):\n",
    "        os.makedirs(output_folder_path)\n",
    "    # Get output_file_path\n",
    "    output_file_path = osp.join(output_folder_path, f'{dataset_name}-{detection_strategy}-heart_feat_selection.csv')\n",
    "    # Generate DataFrame to save to csv format\n",
    "    df = pd.DataFrame.from_dict(results)\n",
    "    df.to_csv(output_file_path, index=False)    "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load dataset and ground-truth as well as dividing groups"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "# -- Uncomment the dataset that you wanna load -- #\n",
    "dataset_name = 'AffectiveROAD'\n",
    "# dataset_name = 'WESAD_CHEST'\n",
    "# dataset_name = 'WESAD_WRIST'\n",
    "# dataset_name = 'DCU_NVT_EXP1'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "dataset, ground_truth, groups = load_dataset(dataset_name) # Load dataset and ground-truths"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{0, 1, -1}\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Define stress detection strategies"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "# -- Uncomment the detection strategy that you wanna use to detect -- #\n",
    "# detection_strategy = 'logistic_regression'\n",
    "detection_strategy = 'random_forest'\n",
    "# detection_strategy = 'svm'\n",
    "# detection_strategy = 'mlp'\n",
    "# detection_strategy = 'knn'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "source": [
    "SCORING = 'balanced_accuracy'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Build General Cross-population Stress Detector"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "source": [
    "clf = BinaryClassifier(dataset, ground_truth, detection_strategy, logo_validation = True, groups = groups, scoring = SCORING)\n",
    "results, feature_importances = clf.exec_classifier() # Build classifier and return prediction results"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "15it [02:57, 11.85s/it]\n"
     ]
    }
   ],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "source": [
    "_feature_importances = np.array([np.argsort(x)[-20:][::-1] for x in feature_importances])\n",
    "from collections import Counter\n",
    "aaa = dict(Counter(_feature_importances.ravel()))\n",
    "print(aaa)\n",
    "print(sorted(aaa))\n",
    "print(len(aaa))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{1: 15, 6: 15, 21: 15, 22: 15, 5: 15, 0: 15, 2: 15, 10: 15, 3: 15, 7: 15, 23: 15, 16: 15, 17: 15, 8: 15, 9: 15, 24: 15, 4: 15, 18: 15, 20: 15, 14: 3, 11: 8, 12: 4}\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 16, 17, 18, 20, 21, 22, 23, 24]\n",
      "22\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "# Save results\n",
    "# detector_type = 'General'\n",
    "# dump_result_to_csv(results, dataset_name, detection_strategy, detector_type)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Build Person-specific Stress Detector"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "source": [
    "logo = LeaveOneGroupOut()\n",
    "balanced_accs = []\n",
    "test_groups = []\n",
    "for _, test_index in tqdm(logo.split(dataset, ground_truth, groups)):\n",
    "    user_dataset, user_ground_truth = dataset[test_index], ground_truth[test_index] # Get personal statistical features and ground-truths of a user\n",
    "\n",
    "    # Re-initialize classifier when iterating a new user\n",
    "    clf = BinaryClassifier(user_dataset, user_ground_truth, detection_strategy, cross_validation = True, scoring = SCORING)\n",
    "    balanced_acc = clf.exec_classifier()\n",
    "\n",
    "    if balanced_acc == -1:\n",
    "        print(groups[test_index][0])\n",
    "        continue # Ignore this user as it only contains one class\n",
    "\n",
    "    # Save user_id and his/her corresponding predicted results\n",
    "    balanced_accs.append(balanced_acc)\n",
    "    test_groups.append(groups[test_index][0])\n",
    "results = { 'groups': test_groups, 'balanced_accurary_score': balanced_accs }"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "0it [00:00, ?it/s]/home/nmduy/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_split.py:293: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 89 90\n",
      " 91 92 93 94]\n",
      "random_forest best grid search score: 1.0 with params - {'class_weight': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 500}\n",
      "[ 22  23  24  25  26  27  28  29  30  31  32  33  34  35  36  37  38  39\n",
      "  40  41  42  95  96  97  98  99 100 101]\n",
      "random_forest best grid search score: 1.0 with params - {'class_weight': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 500}\n",
      "[ 43  44  45  46  47  48  49  50  51  52  53  54  55  56  57  58  59  60\n",
      "  61  62  63 102 103 104 105 106 107 108]\n",
      "random_forest best grid search score: 1.0 with params - {'class_weight': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 500}\n",
      "[ 64  65  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81\n",
      "  82  83  84 109 110 111 112 113 114 115]\n",
      "random_forest best grid search score: 1.0 with params - {'class_weight': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 500}\n",
      "[ 85  86  87  88 116 117 118 119 120 121 122 123 124 125 126 127 128 129\n",
      " 130 131 132 133 134 135 136 137 138 139]\n",
      "random_forest best grid search score: 1.0 with params - {'class_weight': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 500}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "1it [01:12, 72.22s/it]/home/nmduy/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_split.py:293: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 56 57\n",
      " 58 59 60 61]\n",
      "random_forest best grid search score: 1.0 with params - {'class_weight': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 500}\n",
      "[22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 62 63 64\n",
      " 65 66 67 68]\n",
      "random_forest best grid search score: 1.0 with params - {'class_weight': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 500}\n",
      "[43 44 45 46 47 48 49 50 51 52 53 54 55 69 70 71 72 73 74 87 88 89 90 91\n",
      " 92 93 94]\n",
      "random_forest best grid search score: 1.0 with params - {'class_weight': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 500}\n",
      "[ 75  76  77  78  79  80  95  96  97  98  99 100 101 102 103 104 105 106\n",
      " 107 108 109 110 111 112 113 114 115]\n",
      "random_forest best grid search score: 1.0 with params - {'class_weight': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 500}\n",
      "[ 81  82  83  84  85  86 116 117 118 119 120 121 122 123 124 125 126 127\n",
      " 128 129 130 131 132 133 134 135 136]\n",
      "random_forest best grid search score: 1.0 with params - {'class_weight': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 500}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2it [02:24, 72.34s/it]/home/nmduy/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_split.py:293: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 90 91\n",
      " 92 93 94 95]\n",
      "random_forest best grid search score: 1.0 with params - {'class_weight': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 500}\n",
      "[ 22  23  24  25  26  27  28  29  30  31  32  33  34  35  36  37  38  39\n",
      "  40  41  42  43  96  97  98  99 100 101]\n",
      "random_forest best grid search score: 1.0 with params - {'class_weight': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 500}\n",
      "[ 44  45  46  47  48  49  50  51  52  53  54  55  56  57  58  59  60  61\n",
      "  62  63  64 102 103 104 105 106 107 108]\n",
      "random_forest best grid search score: 1.0 with params - {'class_weight': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 500}\n",
      "[ 65  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82\n",
      "  83  84  85 109 110 111 112 113 114]\n",
      "random_forest best grid search score: 1.0 with params - {'class_weight': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 500}\n",
      "[ 86  87  88  89 115 116 117 118 119 120 121 122 123 124 125 126 127 128\n",
      " 129 130 131 132 133 134 135 136 137]\n",
      "random_forest best grid search score: 1.0 with params - {'class_weight': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 500}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "3it [03:37, 72.29s/it]/home/nmduy/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_split.py:293: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 56 57\n",
      " 58 59 60 61]\n",
      "random_forest best grid search score: 1.0 with params - {'class_weight': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 500}\n",
      "[22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 62 63 64\n",
      " 65 66 67 68]\n",
      "random_forest best grid search score: 1.0 with params - {'class_weight': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 500}\n",
      "[43 44 45 46 47 48 49 50 51 52 53 54 55 69 70 71 72 73 74 87 88 89 90 91\n",
      " 92 93 94]\n",
      "random_forest best grid search score: 1.0 with params - {'class_weight': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 500}\n",
      "[ 75  76  77  78  79  80  95  96  97  98  99 100 101 102 103 104 105 106\n",
      " 107 108 109 110 111 112 113 114 115]\n",
      "random_forest best grid search score: 1.0 with params - {'class_weight': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 500}\n",
      "[ 81  82  83  84  85  86 116 117 118 119 120 121 122 123 124 125 126 127\n",
      " 128 129 130 131 132 133 134 135 136]\n",
      "random_forest best grid search score: 1.0 with params - {'class_weight': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 500}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "4it [04:49, 72.46s/it]/home/nmduy/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_split.py:293: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 89 90\n",
      " 91 92 93 94]\n",
      "random_forest best grid search score: 1.0 with params - {'class_weight': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 500}\n",
      "[ 22  23  24  25  26  27  28  29  30  31  32  33  34  35  36  37  38  39\n",
      "  40  41  42  95  96  97  98  99 100 101]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "4it [05:08, 77.12s/it]\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-96408288daa1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m# Re-initialize classifier when iterating a new user\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBinaryClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser_ground_truth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdetection_strategy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcross_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSCORING\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mbalanced_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexec_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mbalanced_acc\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PhD_Work/StressDetection/EDA_Stress_Classifier/classifiers.py\u001b[0m in \u001b[0;36mexec_classifier\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mexec_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_validation\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 207\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_validator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    208\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogo_validation\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleave_one_group_out_validator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PhD_Work/StressDetection/EDA_Stress_Classifier/classifiers.py\u001b[0m in \u001b[0;36mcross_validator\u001b[0;34m(self, method)\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__transform_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Feature scaling if possible\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m             \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__run_grid_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m             \u001b[0;31m# Fit the classifier into test set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PhD_Work/StressDetection/EDA_Stress_Classifier/classifiers.py\u001b[0m in \u001b[0;36m__run_grid_search\u001b[0;34m(self, method, X_train, y_train)\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mparams\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhyper_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m             \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 192\u001b[0;31m             \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    193\u001b[0m             \u001b[0my_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m             \u001b[0mba_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_preds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/nmduy/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    374\u001b[0m                 \u001b[0mrandom_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMAX_INT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m             trees = [self._make_estimator(append=False,\n\u001b[0m\u001b[1;32m    377\u001b[0m                                           random_state=random_state)\n\u001b[1;32m    378\u001b[0m                      for i in range(n_more_estimators)]\n",
      "\u001b[0;32m/home/nmduy/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    374\u001b[0m                 \u001b[0mrandom_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMAX_INT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m             trees = [self._make_estimator(append=False,\n\u001b[0m\u001b[1;32m    377\u001b[0m                                           random_state=random_state)\n\u001b[1;32m    378\u001b[0m                      for i in range(n_more_estimators)]\n",
      "\u001b[0;32m/home/nmduy/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_base.py\u001b[0m in \u001b[0;36m_make_estimator\u001b[0;34m(self, append, random_state)\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0msub\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mestimators\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m         \"\"\"\n\u001b[0;32m--> 151\u001b[0;31m         \u001b[0mestimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_estimator_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m         estimator.set_params(**{p: getattr(self, p)\n\u001b[1;32m    153\u001b[0m                                 for p in self.estimator_params})\n",
      "\u001b[0;32m/home/nmduy/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m                           FutureWarning)\n\u001b[1;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/nmduy/anaconda3/lib/python3.8/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mclone\u001b[0;34m(estimator, safe)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0mklass\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m     \u001b[0mnew_object_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnew_object_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0mnew_object_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msafe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/nmduy/anaconda3/lib/python3.8/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mget_params\u001b[0;34m(self, deep)\u001b[0m\n\u001b[1;32m    203\u001b[0m         \"\"\"\n\u001b[1;32m    204\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_param_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/nmduy/anaconda3/lib/python3.8/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_get_param_names\u001b[0;34m(cls)\u001b[0m\n\u001b[1;32m    172\u001b[0m         \u001b[0;31m# introspect the constructor arguments to find the model parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0;31m# to represent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m         \u001b[0minit_signature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m         \u001b[0;31m# Consider the constructor parameters excluding 'self'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m         parameters = [p for p in init_signature.parameters.values()\n",
      "\u001b[0;32m/home/nmduy/anaconda3/lib/python3.8/inspect.py\u001b[0m in \u001b[0;36msignature\u001b[0;34m(obj, follow_wrapped)\u001b[0m\n\u001b[1;32m   3091\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfollow_wrapped\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3092\u001b[0m     \u001b[0;34m\"\"\"Get a signature object for the passed callable.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3093\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mSignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfollow_wrapped\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_wrapped\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3094\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3095\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/nmduy/anaconda3/lib/python3.8/inspect.py\u001b[0m in \u001b[0;36mfrom_callable\u001b[0;34m(cls, obj, follow_wrapped)\u001b[0m\n\u001b[1;32m   2840\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfrom_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfollow_wrapped\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2841\u001b[0m         \u001b[0;34m\"\"\"Constructs Signature for the given callable object.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2842\u001b[0;31m         return _signature_from_callable(obj, sigcls=cls,\n\u001b[0m\u001b[1;32m   2843\u001b[0m                                         follow_wrapper_chains=follow_wrapped)\n\u001b[1;32m   2844\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/nmduy/anaconda3/lib/python3.8/inspect.py\u001b[0m in \u001b[0;36m_signature_from_callable\u001b[0;34m(obj, follow_wrapper_chains, skip_bound_arg, sigcls)\u001b[0m\n\u001b[1;32m   2290\u001b[0m         \u001b[0;31m# If it's a pure Python function, or an object that is duck type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2291\u001b[0m         \u001b[0;31m# of a Python function (Cython functions, for instance), then:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2292\u001b[0;31m         return _signature_from_function(sigcls, obj,\n\u001b[0m\u001b[1;32m   2293\u001b[0m                                         skip_bound_arg=skip_bound_arg)\n\u001b[1;32m   2294\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/nmduy/anaconda3/lib/python3.8/inspect.py\u001b[0m in \u001b[0;36m_signature_from_function\u001b[0;34m(cls, func, skip_bound_arg)\u001b[0m\n\u001b[1;32m   2183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2184\u001b[0m         \u001b[0mannotation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mannotations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_empty\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2185\u001b[0;31m         parameters.append(Parameter(name, annotation=annotation,\n\u001b[0m\u001b[1;32m   2186\u001b[0m                                     \u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_KEYWORD_ONLY\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2187\u001b[0m                                     default=default))\n",
      "\u001b[0;32m/home/nmduy/anaconda3/lib/python3.8/inspect.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, kind, default, annotation)\u001b[0m\n\u001b[1;32m   2481\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'value {kind!r} is not a valid Parameter.kind'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2482\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdefault\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_empty\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2483\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_kind\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0m_VAR_POSITIONAL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_VAR_KEYWORD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2484\u001b[0m                 \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'{} parameters cannot have default values'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2485\u001b[0m                 \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_kind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescription\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Save results\n",
    "detector_type = 'Personal'\n",
    "dump_result_to_csv(results, dataset_name, detection_strategy, detector_type)"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a1d5b9100ccb4936a513a4c2e96581413c43726381ca42ceaddfd68a024f20b1"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.3 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}