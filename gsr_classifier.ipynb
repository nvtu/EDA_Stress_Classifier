{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.7.6 64-bit",
   "display_name": "Python 3.7.6 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "69a7ec1f19fe8e6b4d60bff3a060a39e42b8b78906aa04442e53246e4bcaf9b9"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import os.path as osp\n",
    "import neurokit2 as nk\n",
    "from DatasetLoader.dataset_loader import DatasetLoader\n",
    "from DatasetLoader.signal_processing import *\n",
    "import configparser\n",
    "from sklearn.model_selection import GroupKFold, StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.feature_selection import RFECV, SelectFromModel\n",
    "import matplotlib.pyplot as plt\n",
    "from Classifiers.classifier_strategy import TryMLClassifierStrategy\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from collections import defaultdict\n",
    "from typing import Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_loader = DatasetLoader()\n",
    "collected_gsr_data, ground_truth = dataset_loader.load_collected_gsr_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Aggrgate dataset to seconds\n",
    "agg_gsr_data = dataset_loader.aggregate_gsr_dataset(collected_gsr_data, ['MICROSIEMENS', 'SCR', 'SCR/MIN'])\n",
    "# Divide the data into intervals\n",
    "agg_interval_gsr_data, agg_interval_ground_truth, agg_interval_group = dataset_loader.divide_into_intervals(agg_gsr_data, ground_truth, 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "agg_interval_gsr_data = select_single_signal(agg_interval_gsr_data, 0)"
   ]
  },
  {
   "source": [
    "## General cross-population stress detection model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Aggregated data + One-minute interval split"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Number of subjects: 11\nNumber of samples: 639\n"
     ]
    }
   ],
   "source": [
    "flatten_agg_data = dataset_loader.flatten(agg_interval_gsr_data)\n",
    "flatten_agg_ground_truth = dataset_loader.flatten(agg_interval_ground_truth)\n",
    "flatten_agg_group = dataset_loader.flatten(agg_interval_group)\n",
    "print(f\"Number of subjects: {len(list(set(flatten_agg_group)))}\")\n",
    "print(f\"Number of samples: {len(flatten_agg_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess_data(flatten_agg_data: np.array, flatten_agg_ground_truth: np.array, flatten_agg_group: np.array = None, sampling_rate: int = 5) -> Tuple[ np.array, np.array, np.array ]:\n",
    "    # Remove the cut with less than 50 values\n",
    "    filtered_agg_index = [item_index for item_index, microsiemens in enumerate(flatten_agg_data) if len(microsiemens) >= 50]\n",
    "    flatten_agg_data = flatten_agg_data[filtered_agg_index]\n",
    "    flatten_agg_ground_truth = flatten_agg_ground_truth[filtered_agg_index]\n",
    "    if flatten_agg_group is not None:\n",
    "        flatten_agg_group = flatten_agg_group[filtered_agg_index]\n",
    "\n",
    "    # Fill the missing values by constant = 0 (due to device error during data collection process)\n",
    "    imp_constant = SimpleImputer(strategy='constant', fill_value=0)\n",
    "    imputed_agg_data = np.array([imp_constant.fit_transform(microsiemens.reshape(-1, 1)).flatten() for microsiemens in flatten_agg_data])\n",
    "\n",
    "    # Normalize the features before processing\n",
    "    scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "    scaled_agg_data = np.array([scaler.fit_transform(microsiemens.reshape(-1, 1)).flatten() for microsiemens in imputed_agg_data])\n",
    "    return scaled_agg_data, flatten_agg_ground_truth, flatten_agg_group\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(preprocessed_data: np.array, sampling_rate: int = 5) -> np.array:\n",
    "    # Extract features from the data\n",
    "    processed_features = [extract_gsr_features(microsiemens, sampling_rate=sampling_rate) for microsiemens in preprocessed_data]\n",
    "\n",
    "    # Extract statistic features\n",
    "    statistic_features = np.array([statistics_gsr_signal_features(feat) for feat in processed_features])\n",
    "    return statistic_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_data, preprocessed_ground_truth, preprocessed_groups = preprocess_data(flatten_agg_data, flatten_agg_ground_truth, flatten_agg_group=flatten_agg_group)\n",
    "statistic_features = extract_features(preprocessed_data)"
   ]
  },
  {
   "source": [
    "### Binary Classification"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "binary_ground_truth = np.array([0 if value[0] < 2 else 1 for value in preprocessed_ground_truth])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = statistic_features\n",
    "y = binary_ground_truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "try_ml_strategies = TryMLClassifierStrategy(X, y, groups=preprocessed_groups)\n",
    "try_ml_strategies.try_different_strategies(group_validation = True)"
   ]
  },
  {
   "source": [
    "### Detailed level-of-stress Classification"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_label_ground_truth = np.array([value[0] for value in preprocessed_ground_truth])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = statistic_features\n",
    "y = multi_label_ground_truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Try Logistic Regression...\n",
      "Mean accuracy of train set: 0.46309590974025444\n",
      "Mean accuracy of test set: 0.3959981296096439\n",
      "--------------------------------------\n",
      "Try Random Forests...\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.36560979963253787\n",
      "13 features remain\n",
      "------After ensemble feature selection------\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.3889948478119741\n",
      "--------------------------------------\n",
      "Try Extra Trees Classifier...\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.36843933360624215\n",
      "13 features remain\n",
      "------After ensemble feature selection------\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.3862223421367108\n",
      "--------------------------------------\n",
      "Try SVM Classifier...\n",
      "Mean accuracy of train set: 0.46396284151821715\n",
      "Mean accuracy of test set: 0.41823485872832755\n",
      "--------------------------------------\n",
      "Try MLPClassifier...\n",
      "Mean accuracy of train set: 0.49270179906356226\n",
      "Mean accuracy of test set: 0.3944537136965778\n",
      "--------------------------------------\n",
      "Try 10-nearest-neighbors...\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.3764465546637777\n",
      "--------------------------------------\n",
      "Try decision trees...\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.31025048344835476\n",
      "--------------------------------------\n",
      "Try XGBoostClassifier...\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.35260717529706403\n"
     ]
    }
   ],
   "source": [
    "try_ml_strategies = TryMLClassifierStrategy(X, y, groups=preprocessed_groups, multiclass=True)\n",
    "try_ml_strategies.try_different_strategies(group_validation = True)"
   ]
  },
  {
   "source": [
    "## Person-specific stress detection model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Binary classification"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare personal-specific stress detection model\n",
    "person_specific_dataset = defaultdict(dict)\n",
    "person_specific_ground_truth = defaultdict(dict)\n",
    "for participant_id, data in agg_gsr_data.items():\n",
    "    person_specific_data, person_specific_gt = dataset_loader.prepare_person_specific_dataset(data, ground_truth)\n",
    "    person_specific_dataset[participant_id] = person_specific_data\n",
    "    person_specific_ground_truth[participant_id] = person_specific_gt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Processing A\n",
      "Try Logistic Regression...\n",
      "Mean accuracy of train set: 0.75\n",
      "Mean accuracy of test set: 0.7000000000000001\n",
      "7 features remain\n",
      "------After recursive feature elimination------\n",
      "Mean accuracy of train set: 0.75\n",
      "Mean accuracy of test set: 0.7000000000000001\n",
      "--------------------------------------\n",
      "Try Random Forests...\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.6\n",
      "12 features remain\n",
      "------After ensemble feature selection------\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.5833333333333334\n",
      "--------------------------------------\n",
      "Try Extra Trees Classifier...\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.6166666666666666\n",
      "12 features remain\n",
      "------After ensemble feature selection------\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.6166666666666667\n",
      "--------------------------------------\n",
      "Try SVM Classifier...\n",
      "Mean accuracy of train set: 0.8333333333333334\n",
      "Mean accuracy of test set: 0.6833333333333332\n",
      "--------------------------------------\n",
      "Try MLPClassifier...\n",
      "Mean accuracy of train set: 0.6166666666666667\n",
      "Mean accuracy of test set: 0.6166666666666667\n",
      "--------------------------------------\n",
      "Try 10-nearest-neighbors...\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.65\n",
      "--------------------------------------\n",
      "Try decision trees...\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.6333333333333333\n",
      "--------------------------------------\n",
      "Try XGBoostClassifier...\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.6166666666666667\n",
      "*****************************************\n",
      "Processing B\n",
      "Try Logistic Regression...\n",
      "Mean accuracy of train set: 0.7822822822822824\n",
      "Mean accuracy of test set: 0.8196881091617932\n",
      "4 features remain\n",
      "------After recursive feature elimination------\n",
      "Mean accuracy of train set: 0.7822822822822824\n",
      "Mean accuracy of test set: 0.8011695906432749\n",
      "--------------------------------------\n",
      "Try Random Forests...\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.6900584795321638\n",
      "12 features remain\n",
      "------After ensemble feature selection------\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.6530214424951267\n",
      "--------------------------------------\n",
      "Try Extra Trees Classifier...\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.7076023391812866\n",
      "12 features remain\n",
      "------After ensemble feature selection------\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.6715399610136452\n",
      "--------------------------------------\n",
      "Try SVM Classifier...\n",
      "Mean accuracy of train set: 0.8183183183183184\n",
      "Mean accuracy of test set: 0.7826510721247564\n",
      "--------------------------------------\n",
      "Try MLPClassifier...\n",
      "Mean accuracy of train set: 0.6909409409409409\n",
      "Mean accuracy of test set: 0.6910331384015594\n",
      "--------------------------------------\n",
      "Try 10-nearest-neighbors...\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.7641325536062378\n",
      "--------------------------------------\n",
      "Try decision trees...\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.5818713450292398\n",
      "--------------------------------------\n",
      "Try XGBoostClassifier...\n",
      "Mean accuracy of train set: 0.990990990990991\n",
      "Mean accuracy of test set: 0.6159844054580896\n",
      "*****************************************\n",
      "Processing C\n",
      "Processing D\n",
      "Try Logistic Regression...\n",
      "Mean accuracy of train set: 0.601328903654485\n",
      "Mean accuracy of test set: 0.4985569985569986\n",
      "1 features remain\n",
      "------After recursive feature elimination------\n",
      "Mean accuracy of train set: 0.5937615356220007\n",
      "Mean accuracy of test set: 0.5937950937950939\n",
      "--------------------------------------\n",
      "Try Random Forests...\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.5937950937950939\n",
      "12 features remain\n",
      "------After ensemble feature selection------\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.5779220779220778\n",
      "--------------------------------------\n",
      "Try Extra Trees Classifier...\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.6558441558441558\n",
      "13 features remain\n",
      "------After ensemble feature selection------\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.5613275613275613\n",
      "--------------------------------------\n",
      "Try SVM Classifier...\n",
      "Mean accuracy of train set: 0.7266519010705057\n",
      "Mean accuracy of test set: 0.5937950937950939\n",
      "--------------------------------------\n",
      "Try MLPClassifier...\n",
      "Mean accuracy of train set: 0.5540789959394611\n",
      "Mean accuracy of test set: 0.5923520923520923\n",
      "--------------------------------------\n",
      "Try 10-nearest-neighbors...\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.5772005772005772\n",
      "--------------------------------------\n",
      "Try decision trees...\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.5937950937950938\n",
      "--------------------------------------\n",
      "Try XGBoostClassifier...\n",
      "Mean accuracy of train set: 0.9922480620155039\n",
      "Mean accuracy of test set: 0.562049062049062\n",
      "*****************************************\n",
      "Processing E\n",
      "Try Logistic Regression...\n",
      "Mean accuracy of train set: 0.6666666666666666\n",
      "Mean accuracy of test set: 0.6470588235294118\n",
      "9 features remain\n",
      "------After recursive feature elimination------\n",
      "Mean accuracy of train set: 0.6666666666666666\n",
      "Mean accuracy of test set: 0.6470588235294118\n",
      "--------------------------------------\n",
      "Try Random Forests...\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.6666666666666666\n",
      "13 features remain\n",
      "------After ensemble feature selection------\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.6666666666666666\n",
      "--------------------------------------\n",
      "Try Extra Trees Classifier...\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.5882352941176471\n",
      "13 features remain\n",
      "------After ensemble feature selection------\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.5686274509803922\n",
      "--------------------------------------\n",
      "Try SVM Classifier...\n",
      "Mean accuracy of train set: 0.7745098039215685\n",
      "Mean accuracy of test set: 0.6274509803921569\n",
      "--------------------------------------\n",
      "Try MLPClassifier...\n",
      "Mean accuracy of train set: 0.607843137254902\n",
      "Mean accuracy of test set: 0.607843137254902\n",
      "--------------------------------------\n",
      "Try 10-nearest-neighbors...\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.6274509803921569\n",
      "--------------------------------------\n",
      "Try decision trees...\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.6274509803921569\n",
      "--------------------------------------\n",
      "Try XGBoostClassifier...\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.5490196078431372\n",
      "*****************************************\n",
      "Processing F\n",
      "Try Logistic Regression...\n",
      "Mean accuracy of train set: 0.8220085470085469\n",
      "Mean accuracy of test set: 0.7789473684210527\n",
      "1 features remain\n",
      "------After recursive feature elimination------\n",
      "Mean accuracy of train set: 0.8136752136752138\n",
      "Mean accuracy of test set: 0.8140350877192982\n",
      "--------------------------------------\n",
      "Try Random Forests...\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.7447368421052633\n",
      "13 features remain\n",
      "------After ensemble feature selection------\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.7280701754385964\n",
      "--------------------------------------\n",
      "Try Extra Trees Classifier...\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.7622807017543859\n",
      "13 features remain\n",
      "------After ensemble feature selection------\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.7271929824561404\n",
      "--------------------------------------\n",
      "Try SVM Classifier...\n",
      "Mean accuracy of train set: 0.8136752136752138\n",
      "Mean accuracy of test set: 0.8140350877192982\n",
      "--------------------------------------\n",
      "Try MLPClassifier...\n",
      "Mean accuracy of train set: 0.8136752136752138\n",
      "Mean accuracy of test set: 0.8140350877192982\n",
      "--------------------------------------\n",
      "Try 10-nearest-neighbors...\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.7798245614035088\n",
      "--------------------------------------\n",
      "Try decision trees...\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.6271929824561403\n",
      "--------------------------------------\n",
      "Try XGBoostClassifier...\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.6938596491228072\n",
      "*****************************************\n",
      "Processing G\n",
      "Processing H\n",
      "Processing I\n",
      "Try Logistic Regression...\n",
      "Mean accuracy of train set: 0.903361344537815\n",
      "Mean accuracy of test set: 0.8464052287581699\n",
      "1 features remain\n",
      "------After recursive feature elimination------\n",
      "Mean accuracy of train set: 0.884313725490196\n",
      "Mean accuracy of test set: 0.8464052287581699\n",
      "--------------------------------------\n",
      "Try Random Forests...\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.903050108932462\n",
      "9 features remain\n",
      "------After ensemble feature selection------\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.903050108932462\n",
      "--------------------------------------\n",
      "Try Extra Trees Classifier...\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.903050108932462\n",
      "10 features remain\n",
      "------After ensemble feature selection------\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.903050108932462\n",
      "--------------------------------------\n",
      "Try SVM Classifier...\n",
      "Mean accuracy of train set: 0.922689075630252\n",
      "Mean accuracy of test set: 0.8660130718954249\n",
      "--------------------------------------\n",
      "Try MLPClassifier...\n",
      "Mean accuracy of train set: 0.846218487394958\n",
      "Mean accuracy of test set: 0.8464052287581699\n",
      "--------------------------------------\n",
      "Try 10-nearest-neighbors...\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.8660130718954249\n",
      "--------------------------------------\n",
      "Try decision trees...\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.8257080610021786\n",
      "--------------------------------------\n",
      "Try XGBoostClassifier...\n",
      "Mean accuracy of train set: 0.9904761904761905\n",
      "Mean accuracy of test set: 0.8464052287581699\n",
      "*****************************************\n",
      "Processing J\n",
      "Try Logistic Regression...\n",
      "Mean accuracy of train set: 0.6666666666666666\n",
      "Mean accuracy of test set: 0.5925925925925926\n",
      "3 features remain\n",
      "------After recursive feature elimination------\n",
      "Mean accuracy of train set: 0.6759259259259259\n",
      "Mean accuracy of test set: 0.5740740740740741\n",
      "--------------------------------------\n",
      "Try Random Forests...\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.6666666666666666\n",
      "12 features remain\n",
      "------After ensemble feature selection------\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.6296296296296297\n",
      "--------------------------------------\n",
      "Try Extra Trees Classifier...\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.6851851851851851\n",
      "13 features remain\n",
      "------After ensemble feature selection------\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.6481481481481483\n",
      "--------------------------------------\n",
      "Try SVM Classifier...\n",
      "Mean accuracy of train set: 0.7407407407407408\n",
      "Mean accuracy of test set: 0.7037037037037037\n",
      "--------------------------------------\n",
      "Try MLPClassifier...\n",
      "Mean accuracy of train set: 0.5740740740740741\n",
      "Mean accuracy of test set: 0.5740740740740741\n",
      "--------------------------------------\n",
      "Try 10-nearest-neighbors...\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.5370370370370371\n",
      "--------------------------------------\n",
      "Try decision trees...\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.4444444444444444\n",
      "--------------------------------------\n",
      "Try XGBoostClassifier...\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.5925925925925926\n",
      "*****************************************\n",
      "Processing K\n"
     ]
    }
   ],
   "source": [
    "for participant_id, data in person_specific_dataset.items():\n",
    "    print(f\"Processing {participant_id}\")\n",
    "    person_specific_gt = np.array([0 if value[0] < 2 else 1 for value in person_specific_ground_truth[participant_id]])\n",
    "    if len(list(set(person_specific_gt))) < 2: # If the data contains non-stress value, then continue\n",
    "        continue\n",
    "    person_specific_data, person_specific_gt = dataset_loader.divide_person_specific_data_into_intervals(data, person_specific_gt, num_samples=60)\n",
    "    preprocessed_data, preprocessed_ground_truth, _ = preprocess_data(person_specific_data, person_specific_gt)\n",
    "    person_specific_statistic_features = extract_features(preprocessed_data)\n",
    "    try_ml_strategies = TryMLClassifierStrategy(person_specific_statistic_features, preprocessed_ground_truth)\n",
    "    try_ml_strategies.try_different_strategies(cross_validation = True)\n",
    "    print(\"*****************************************\")"
   ]
  },
  {
   "source": [
    "### Detailed level-of-stress Classification"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Processing A\n",
      "Try Logistic Regression...\n",
      "Mean accuracy of train set: 0.5750000000000001\n",
      "Mean accuracy of test set: 0.5499999999999999\n",
      "1 features remain\n",
      "------After recursive feature elimination------\n",
      "Mean accuracy of train set: 0.6\n",
      "Mean accuracy of test set: 0.6166666666666667\n",
      "--------------------------------------\n",
      "Try Random Forests...\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.5166666666666667\n",
      "13 features remain\n",
      "------After ensemble feature selection------\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.46666666666666673\n",
      "--------------------------------------\n",
      "Try Extra Trees Classifier...\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.43333333333333335\n",
      "13 features remain\n",
      "------After ensemble feature selection------\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.45\n",
      "--------------------------------------\n",
      "Try SVM Classifier...\n",
      "Mean accuracy of train set: 0.7416666666666666\n",
      "Mean accuracy of test set: 0.6\n",
      "--------------------------------------\n",
      "Try MLPClassifier...\n",
      "Mean accuracy of train set: 0.43333333333333335\n",
      "Mean accuracy of test set: 0.43333333333333335\n",
      "--------------------------------------\n",
      "Try 10-nearest-neighbors...\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.6\n",
      "--------------------------------------\n",
      "Try decision trees...\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.45\n",
      "--------------------------------------\n",
      "Try XGBoostClassifier...\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.43333333333333335\n",
      "*****************************************\n",
      "Processing B\n",
      "Try Logistic Regression...\n",
      "Mean accuracy of train set: 0.5455455455455455\n",
      "Mean accuracy of test set: 0.48927875243664715\n",
      "5 features remain\n",
      "------After recursive feature elimination------\n",
      "Mean accuracy of train set: 0.5455455455455455\n",
      "Mean accuracy of test set: 0.5263157894736842\n",
      "--------------------------------------\n",
      "Try Random Forests...\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.4337231968810917\n",
      "13 features remain\n",
      "------After ensemble feature selection------\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.4522417153996101\n",
      "--------------------------------------\n",
      "Try Extra Trees Classifier...\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.4717348927875243\n",
      "13 features remain\n",
      "------After ensemble feature selection------\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.5263157894736842\n",
      "--------------------------------------\n",
      "Try SVM Classifier...\n",
      "Mean accuracy of train set: 0.5728228228228228\n",
      "Mean accuracy of test set: 0.4532163742690058\n",
      "--------------------------------------\n",
      "Try MLPClassifier...\n",
      "Mean accuracy of train set: 0.4364364364364364\n",
      "Mean accuracy of test set: 0.43664717348927873\n",
      "--------------------------------------\n",
      "Try 10-nearest-neighbors...\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.36062378167641324\n",
      "--------------------------------------\n",
      "Try decision trees...\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.3645224171539961\n",
      "--------------------------------------\n",
      "Try XGBoostClassifier...\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.38011695906432746\n",
      "*****************************************\n",
      "Processing C\n",
      "Try Logistic Regression...\n",
      "Mean accuracy of train set: 0.6666666666666666\n",
      "Mean accuracy of test set: 0.5185185185185185\n",
      "1 features remain\n",
      "------After recursive feature elimination------\n",
      "Mean accuracy of train set: 0.6759259259259259\n",
      "Mean accuracy of test set: 0.6666666666666666\n",
      "--------------------------------------\n",
      "Try Random Forests...\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.611111111111111\n",
      "13 features remain\n",
      "------After ensemble feature selection------\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.6296296296296297\n",
      "--------------------------------------\n",
      "Try Extra Trees Classifier...\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.6481481481481483\n",
      "13 features remain\n",
      "------After ensemble feature selection------\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.6481481481481481\n",
      "--------------------------------------\n",
      "Try SVM Classifier...\n",
      "Mean accuracy of train set: 0.75\n",
      "Mean accuracy of test set: 0.5925925925925927\n",
      "--------------------------------------\n",
      "Try MLPClassifier...\n",
      "Mean accuracy of train set: 0.6666666666666666\n",
      "Mean accuracy of test set: 0.6666666666666666\n",
      "--------------------------------------\n",
      "Try 10-nearest-neighbors...\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.6111111111111112\n",
      "--------------------------------------\n",
      "Try decision trees...\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.5370370370370371\n",
      "--------------------------------------\n",
      "Try XGBoostClassifier...\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.48148148148148145\n",
      "*****************************************\n",
      "Processing D\n",
      "Try Logistic Regression...\n",
      "Mean accuracy of train set: 0.5315614617940199\n",
      "Mean accuracy of test set: 0.37662337662337664\n",
      "1 features remain\n",
      "------After recursive feature elimination------\n",
      "Mean accuracy of train set: 0.5\n",
      "Mean accuracy of test set: 0.48412698412698413\n",
      "--------------------------------------\n",
      "Try Random Forests...\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.34487734487734484\n",
      "13 features remain\n",
      "------After ensemble feature selection------\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.34487734487734484\n",
      "--------------------------------------\n",
      "Try Extra Trees Classifier...\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.31385281385281383\n",
      "13 features remain\n",
      "------After ensemble feature selection------\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.36002886002886\n",
      "--------------------------------------\n",
      "Try SVM Classifier...\n",
      "Mean accuracy of train set: 0.5548172757475083\n",
      "Mean accuracy of test set: 0.40692640692640697\n",
      "--------------------------------------\n",
      "Try MLPClassifier...\n",
      "Mean accuracy of train set: 0.5\n",
      "Mean accuracy of test set: 0.5\n",
      "--------------------------------------\n",
      "Try 10-nearest-neighbors...\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.36002886002886\n",
      "--------------------------------------\n",
      "Try decision trees...\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.3441558441558441\n",
      "--------------------------------------\n",
      "Try XGBoostClassifier...\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.2972582972582972\n",
      "*****************************************\n",
      "Processing E\n",
      "Try Logistic Regression...\n",
      "Mean accuracy of train set: 0.5098039215686274\n",
      "Mean accuracy of test set: 0.4313725490196078\n",
      "2 features remain\n",
      "------After recursive feature elimination------\n",
      "Mean accuracy of train set: 0.4803921568627451\n",
      "Mean accuracy of test set: 0.4313725490196078\n",
      "--------------------------------------\n",
      "Try Random Forests...\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.4313725490196078\n",
      "13 features remain\n",
      "------After ensemble feature selection------\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.411764705882353\n",
      "--------------------------------------\n",
      "Try Extra Trees Classifier...\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.39215686274509803\n",
      "13 features remain\n",
      "------After ensemble feature selection------\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.35294117647058826\n",
      "--------------------------------------\n",
      "Try SVM Classifier...\n",
      "Mean accuracy of train set: 0.5882352941176471\n",
      "Mean accuracy of test set: 0.3333333333333333\n",
      "--------------------------------------\n",
      "Try MLPClassifier...\n",
      "Mean accuracy of train set: 0.2843137254901961\n",
      "Mean accuracy of test set: 0.2745098039215686\n",
      "--------------------------------------\n",
      "Try 10-nearest-neighbors...\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.35294117647058815\n",
      "--------------------------------------\n",
      "Try decision trees...\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.392156862745098\n",
      "--------------------------------------\n",
      "Try XGBoostClassifier...\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.35294117647058815\n",
      "*****************************************\n",
      "Processing F\n",
      "Try Logistic Regression...\n",
      "Mean accuracy of train set: 0.5587606837606838\n",
      "Mean accuracy of test set: 0.5421052631578948\n",
      "11 features remain\n",
      "------After recursive feature elimination------\n",
      "Mean accuracy of train set: 0.5587606837606838\n",
      "Mean accuracy of test set: 0.5421052631578948\n",
      "--------------------------------------\n",
      "Try Random Forests...\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.5570175438596491\n",
      "13 features remain\n",
      "------After ensemble feature selection------\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.5745614035087719\n",
      "--------------------------------------\n",
      "Try Extra Trees Classifier...\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.6078947368421053\n",
      "13 features remain\n",
      "------After ensemble feature selection------\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.5561403508771929\n",
      "--------------------------------------\n",
      "Try SVM Classifier...\n",
      "Mean accuracy of train set: 0.6267094017094018\n",
      "Mean accuracy of test set: 0.506140350877193\n",
      "--------------------------------------\n",
      "Try MLPClassifier...\n",
      "Mean accuracy of train set: 0.4745726495726495\n",
      "Mean accuracy of test set: 0.4745614035087719\n",
      "--------------------------------------\n",
      "Try 10-nearest-neighbors...\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.4728070175438597\n",
      "--------------------------------------\n",
      "Try decision trees...\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.356140350877193\n",
      "--------------------------------------\n",
      "Try XGBoostClassifier...\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.4385964912280702\n",
      "*****************************************\n",
      "Processing G\n",
      "Try Logistic Regression...\n",
      "Mean accuracy of train set: 0.7109243697478992\n",
      "Mean accuracy of test set: 0.5762527233115469\n",
      "1 features remain\n",
      "------After recursive feature elimination------\n",
      "Mean accuracy of train set: 0.672829131652661\n",
      "Mean accuracy of test set: 0.5958605664488017\n",
      "--------------------------------------\n",
      "Try Random Forests...\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.5010893246187363\n",
      "13 features remain\n",
      "------After ensemble feature selection------\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.4259259259259259\n",
      "--------------------------------------\n",
      "Try Extra Trees Classifier...\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.4825708061002179\n",
      "13 features remain\n",
      "------After ensemble feature selection------\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.4444444444444445\n",
      "--------------------------------------\n",
      "Try SVM Classifier...\n",
      "Mean accuracy of train set: 0.7784313725490196\n",
      "Mean accuracy of test set: 0.5947712418300654\n",
      "--------------------------------------\n",
      "Try MLPClassifier...\n",
      "Mean accuracy of train set: 0.615686274509804\n",
      "Mean accuracy of test set: 0.5588235294117646\n",
      "--------------------------------------\n",
      "Try 10-nearest-neighbors...\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.5381263616557734\n",
      "--------------------------------------\n",
      "Try decision trees...\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.5196078431372549\n",
      "--------------------------------------\n",
      "Try XGBoostClassifier...\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.4422657952069717\n",
      "*****************************************\n",
      "Processing H\n",
      "Try Logistic Regression...\n",
      "Mean accuracy of train set: 0.5767025089605734\n",
      "Mean accuracy of test set: 0.4986111111111111\n",
      "1 features remain\n",
      "------After recursive feature elimination------\n",
      "Mean accuracy of train set: 0.5878136200716845\n",
      "Mean accuracy of test set: 0.5416666666666666\n",
      "--------------------------------------\n",
      "Try Random Forests...\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.5041666666666668\n",
      "13 features remain\n",
      "------After ensemble feature selection------\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.5013888888888888\n",
      "--------------------------------------\n",
      "Try Extra Trees Classifier...\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.5652777777777778\n",
      "13 features remain\n",
      "------After ensemble feature selection------\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.5444444444444444\n",
      "--------------------------------------\n",
      "Try SVM Classifier...\n",
      "Mean accuracy of train set: 0.7609318996415771\n",
      "Mean accuracy of test set: 0.37222222222222223\n",
      "--------------------------------------\n",
      "Try MLPClassifier...\n",
      "Mean accuracy of train set: 0.5\n",
      "Mean accuracy of test set: 0.5\n",
      "--------------------------------------\n",
      "Try 10-nearest-neighbors...\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.4361111111111111\n",
      "--------------------------------------\n",
      "Try decision trees...\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.4847222222222222\n",
      "--------------------------------------\n",
      "Try XGBoostClassifier...\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.525\n",
      "*****************************************\n",
      "Processing I\n",
      "Try Logistic Regression...\n",
      "Mean accuracy of train set: 0.6246498599439776\n",
      "Mean accuracy of test set: 0.4803921568627451\n",
      "1 features remain\n",
      "------After recursive feature elimination------\n",
      "Mean accuracy of train set: 0.5484593837535013\n",
      "Mean accuracy of test set: 0.5206971677559912\n",
      "--------------------------------------\n",
      "Try Random Forests...\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.5010893246187363\n",
      "13 features remain\n",
      "------After ensemble feature selection------\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.48148148148148145\n",
      "--------------------------------------\n",
      "Try Extra Trees Classifier...\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.5174291938997823\n",
      "13 features remain\n",
      "------After ensemble feature selection------\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.556644880174292\n",
      "--------------------------------------\n",
      "Try SVM Classifier...\n",
      "Mean accuracy of train set: 0.6826330532212886\n",
      "Mean accuracy of test set: 0.5010893246187363\n",
      "--------------------------------------\n",
      "Try MLPClassifier...\n",
      "Mean accuracy of train set: 0.5198879551820729\n",
      "Mean accuracy of test set: 0.289760348583878\n",
      "--------------------------------------\n",
      "Try 10-nearest-neighbors...\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.5010893246187363\n",
      "--------------------------------------\n",
      "Try decision trees...\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.47712418300653586\n",
      "--------------------------------------\n",
      "Try XGBoostClassifier...\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.46187363834422657\n",
      "*****************************************\n",
      "Processing J\n",
      "Try Logistic Regression...\n",
      "Mean accuracy of train set: 0.5555555555555556\n",
      "Mean accuracy of test set: 0.46296296296296297\n",
      "2 features remain\n",
      "------After recursive feature elimination------\n",
      "Mean accuracy of train set: 0.49074074074074076\n",
      "Mean accuracy of test set: 0.38888888888888884\n",
      "--------------------------------------\n",
      "Try Random Forests...\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.6296296296296297\n",
      "12 features remain\n",
      "------After ensemble feature selection------\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.6666666666666666\n",
      "--------------------------------------\n",
      "Try Extra Trees Classifier...\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.5740740740740741\n",
      "12 features remain\n",
      "------After ensemble feature selection------\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.5740740740740741\n",
      "--------------------------------------\n",
      "Try SVM Classifier...\n",
      "Mean accuracy of train set: 0.6666666666666666\n",
      "Mean accuracy of test set: 0.5\n",
      "--------------------------------------\n",
      "Try MLPClassifier...\n",
      "Mean accuracy of train set: 0.48148148148148145\n",
      "Mean accuracy of test set: 0.48148148148148145\n",
      "--------------------------------------\n",
      "Try 10-nearest-neighbors...\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.46296296296296297\n",
      "--------------------------------------\n",
      "Try decision trees...\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.4444444444444444\n",
      "--------------------------------------\n",
      "Try XGBoostClassifier...\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.5555555555555556\n",
      "*****************************************\n",
      "Processing K\n",
      "Try Logistic Regression...\n",
      "Mean accuracy of train set: 0.9301841948900772\n",
      "Mean accuracy of test set: 0.8615196078431372\n",
      "1 features remain\n",
      "------After recursive feature elimination------\n",
      "Mean accuracy of train set: 0.9001782531194295\n",
      "Mean accuracy of test set: 0.8811274509803922\n",
      "--------------------------------------\n",
      "Try Random Forests...\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.8210784313725491\n",
      "10 features remain\n",
      "------After ensemble feature selection------\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.8026960784313726\n",
      "--------------------------------------\n",
      "Try Extra Trees Classifier...\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.8026960784313726\n",
      "13 features remain\n",
      "------After ensemble feature selection------\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.7622549019607843\n",
      "--------------------------------------\n",
      "Try SVM Classifier...\n",
      "Mean accuracy of train set: 0.9301841948900772\n",
      "Mean accuracy of test set: 0.8615196078431372\n",
      "--------------------------------------\n",
      "Try MLPClassifier...\n",
      "Mean accuracy of train set: 0.9001782531194295\n",
      "Mean accuracy of test set: 0.9007352941176471\n",
      "--------------------------------------\n",
      "Try 10-nearest-neighbors...\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.9007352941176471\n",
      "--------------------------------------\n",
      "Try decision trees...\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.801470588235294\n",
      "--------------------------------------\n",
      "Try XGBoostClassifier...\n",
      "Mean accuracy of train set: 0.98989898989899\n",
      "Mean accuracy of test set: 0.9007352941176471\n",
      "*****************************************\n"
     ]
    }
   ],
   "source": [
    "for participant_id, data in person_specific_dataset.items():\n",
    "    print(f\"Processing {participant_id}\")\n",
    "    person_specific_gt = np.array([value[0] for value in person_specific_ground_truth[participant_id]])\n",
    "    if len(list(set(person_specific_gt))) < 2: # If the data contains non-stress value, then continue\n",
    "        continue\n",
    "    person_specific_data, person_specific_gt = dataset_loader.divide_person_specific_data_into_intervals(data, person_specific_gt, num_samples=60)\n",
    "    preprocessed_data, preprocessed_ground_truth, _ = preprocess_data(person_specific_data, person_specific_gt)\n",
    "    person_specific_statistic_features = extract_features(preprocessed_data)\n",
    "    try_ml_strategies = TryMLClassifierStrategy(person_specific_statistic_features, preprocessed_ground_truth)\n",
    "    try_ml_strategies.try_different_strategies(cross_validation = True)\n",
    "    print(\"*****************************************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}