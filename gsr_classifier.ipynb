{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.7.6 64-bit",
   "display_name": "Python 3.7.6 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "69a7ec1f19fe8e6b4d60bff3a060a39e42b8b78906aa04442e53246e4bcaf9b9"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "SyntaxError",
     "evalue": "invalid syntax (dataset_loader.py, line 21)",
     "traceback": [
      "Traceback \u001b[1;36m(most recent call last)\u001b[0m:\n",
      "  File \u001b[0;32m\"C:\\Users\\Asus\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\IPython\\core\\interactiveshell.py\"\u001b[0m, line \u001b[0;32m3331\u001b[0m, in \u001b[0;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-1-4006e0569949>\"\u001b[1;36m, line \u001b[1;32m4\u001b[1;36m, in \u001b[1;35m<module>\u001b[1;36m\u001b[0m\n\u001b[1;33m    from DatasetLoader.dataset_loader import DatasetLoader\u001b[0m\n",
      "\u001b[1;36m  File \u001b[1;32m\"d:\\DCU\\CAPT\\Experiment_Protocol_1\\CODE\\DatasetLoader\\dataset_loader.py\"\u001b[1;36m, line \u001b[1;32m21\u001b[0m\n\u001b[1;33m    self.wesad_gsr_groundtruth_path = osp.join(osp.dirname(self.))\u001b[0m\n\u001b[1;37m                                                                ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import os.path as osp\n",
    "from DatasetLoader.dataset_loader import DatasetLoader\n",
    "from DatasetLoader.signal_processing import *\n",
    "from sklearn.impute import SimpleImputer\n",
    "from Classifiers.classifier_strategy import TryMLClassifierStrategy\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from collections import defaultdict\n",
    "from typing import Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_loader = DatasetLoader()\n",
    "collected_gsr_data, ground_truth = dataset_loader.load_collected_gsr_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "single_signal_data = select_single_signal(collected_gsr_data, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Aggrgate dataset to seconds\n",
    "# agg_gsr_data = dataset_loader.aggregate_gsr_dataset(collected_gsr_data, ['MICROSIEMENS', 'SCR', 'SCR/MIN'])\n",
    "# Divide the data into intervals\n",
    "# agg_interval_gsr_data, agg_interval_ground_truth, agg_interval_group = dataset_loader.divide_into_intervals(agg_gsr_data, ground_truth, 60, sampling_rate = 5)\n",
    "interval_gsr_data, interval_ground_truth, interval_group = dataset_loader.divide_into_intervals(single_signal_data, ground_truth, 60, sampling_rate = 5)"
   ]
  },
  {
   "source": [
    "## General cross-population stress detection model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### One-minute interval split"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Number of subjects: 11\nNumber of samples: 640\n"
     ]
    }
   ],
   "source": [
    "flatten_agg_data = dataset_loader.flatten(interval_gsr_data)\n",
    "flatten_agg_ground_truth = dataset_loader.flatten(interval_ground_truth)\n",
    "flatten_agg_group = dataset_loader.flatten(interval_group)\n",
    "print(f\"Number of subjects: {len(list(set(flatten_agg_group)))}\")\n",
    "print(f\"Number of samples: {len(flatten_agg_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess_data(flatten_agg_data: np.array, flatten_agg_ground_truth: np.array, flatten_agg_group: np.array = None, sampling_rate: int = 5) -> Tuple[ np.array, np.array, np.array ]:\n",
    "    # Remove the cut with less than 50 values\n",
    "    filtered_agg_index = [item_index for item_index, microsiemens in enumerate(flatten_agg_data) if len(microsiemens) >= 250]\n",
    "    flatten_agg_data = flatten_agg_data[filtered_agg_index]\n",
    "    flatten_agg_ground_truth = flatten_agg_ground_truth[filtered_agg_index]\n",
    "    if flatten_agg_group is not None:\n",
    "        flatten_agg_group = flatten_agg_group[filtered_agg_index]\n",
    "\n",
    "    # Fill the missing values by constant = 0 (due to device error during data collection process)\n",
    "    imp_constant = SimpleImputer(strategy='constant', fill_value=0)\n",
    "    imputed_agg_data = np.array([imp_constant.fit_transform(microsiemens.reshape(-1, 1)).flatten() for microsiemens in flatten_agg_data])\n",
    "\n",
    "    # # Normalize the features before processing\n",
    "    # scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "    # scaled_agg_data = np.array([scaler.fit_transform(microsiemens.reshape(-1, 1)).flatten() for microsiemens in imputed_agg_data])\n",
    "    # return scaled_agg_data, flatten_agg_ground_truth, flatten_agg_group\n",
    "    return imputed_agg_data, flatten_agg_ground_truth, flatten_agg_group\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(preprocessed_data: np.array, sampling_rate: int = 5) -> np.array:\n",
    "    # Extract features from the data\n",
    "    processed_features = [extract_gsr_features(microsiemens, sampling_rate=sampling_rate) for microsiemens in preprocessed_data]\n",
    "\n",
    "    # Extract statistic features\n",
    "    statistic_features = np.array([statistics_gsr_signal_features(feat) for feat in processed_features])\n",
    "    return statistic_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_data, preprocessed_ground_truth, preprocessed_groups = preprocess_data(flatten_agg_data, flatten_agg_ground_truth, flatten_agg_group=flatten_agg_group)\n",
    "statistic_features = extract_features(preprocessed_data)"
   ]
  },
  {
   "source": [
    "### Binary Classification"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "binary_ground_truth = np.array([0 if value[0] < 2 else 1 for value in preprocessed_ground_truth])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = statistic_features\n",
    "y = binary_ground_truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Try Logistic Regression...\n",
      "Groups: [['E', 'C', 'D'], ['J', 'K', 'I', 'A'], ['H', 'B', 'G', 'F']]\n",
      "ROC AUC Score: [0.4207828518173346, 0.44581618655692734, 0.46972049689441]\n",
      "Mean accuracy of train set: 0.7709077253193818\n",
      "Mean accuracy of test set: 0.7396081001547862\n",
      "--------------------------------------\n",
      "Try Random Forests...\n",
      "Groups: [['E', 'C', 'D'], ['J', 'K', 'I', 'A'], ['H', 'B', 'G', 'F']]\n",
      "ROC AUC Score: [0.3463031997514755, 0.43941472336534065, 0.33880046583850937]\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.7110820628600019\n",
      "25 features remain\n",
      "------After ensemble feature selection------\n",
      "Groups: [['E', 'C', 'D'], ['J', 'K', 'I', 'A'], ['H', 'B', 'G', 'F']]\n",
      "ROC AUC Score: [0.3487107797452625, 0.43021262002743477, 0.3962538819875776]\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.7051066687617243\n",
      "--------------------------------------\n",
      "Try Extra Trees Classifier...\n",
      "Groups: [['E', 'C', 'D'], ['J', 'K', 'I', 'A'], ['H', 'B', 'G', 'F']]\n",
      "ROC AUC Score: [0.38560111835973904, 0.41460905349794236, 0.3449145962732919]\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.71105294569252\n",
      "27 features remain\n",
      "------After ensemble feature selection------\n",
      "Groups: [['E', 'C', 'D'], ['J', 'K', 'I', 'A'], ['H', 'B', 'G', 'F']]\n",
      "ROC AUC Score: [0.4120844982913949, 0.4684499314128943, 0.32608695652173914]\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.7055067283054705\n",
      "--------------------------------------\n",
      "Try SVM Classifier...\n",
      "Groups: [['E', 'C', 'D'], ['J', 'K', 'I', 'A'], ['H', 'B', 'G', 'F']]\n",
      "ROC AUC Score: [0.5455110282696489, 0.5553269318701417, 0.41479037267080743]\n",
      "Mean accuracy of train set: 0.9772101766803364\n",
      "Mean accuracy of test set: 0.7480672403265533\n",
      "--------------------------------------\n",
      "Try MLPClassifier...\n",
      "Groups: [['E', 'C', 'D'], ['J', 'K', 'I', 'A'], ['H', 'B', 'G', 'F']]\n",
      "ROC AUC Score: [0.4243553898726312, 0.4794238683127572, 0.4493400621118012]\n",
      "Mean accuracy of train set: 0.791252022766483\n",
      "Mean accuracy of test set: 0.6618916234905591\n",
      "--------------------------------------\n",
      "Try 10-nearest-neighbors...\n",
      "Groups: [['E', 'C', 'D'], ['J', 'K', 'I', 'A'], ['H', 'B', 'G', 'F']]\n",
      "ROC AUC Score: [0.4346846846846847, 0.4873113854595336, 0.46671195652173914]\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.6962993286166967\n",
      "--------------------------------------\n",
      "Try decision trees...\n",
      "Groups: [['E', 'C', 'D'], ['J', 'K', 'I', 'A'], ['H', 'B', 'G', 'F']]\n",
      "ROC AUC Score: [0.44167443305374343, 0.49691358024691357, 0.41809006211180116]\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.580016560604369\n",
      "--------------------------------------\n",
      "Try XGBoostClassifier...\n",
      "Groups: [['E', 'C', 'D'], ['J', 'K', 'I', 'A'], ['H', 'B', 'G', 'F']]\n",
      "ROC AUC Score: [0.34902143522833173, 0.44112940100594417, 0.3612189440993789]\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.6504549514346322\n",
      "--------------------------------------\n",
      "Try Linear Discriminate Analysis...\n",
      "Groups: [['E', 'C', 'D'], ['J', 'K', 'I', 'A'], ['H', 'B', 'G', 'F']]\n",
      "ROC AUC Score: [0.4904473438956198, 0.44655921353452227, 0.47214673913043476]\n",
      "Mean accuracy of train set: 0.6753105256490347\n",
      "Mean accuracy of test set: 0.6337908002155704\n"
     ]
    }
   ],
   "source": [
    "try_ml_strategies = TryMLClassifierStrategy(X, y, groups=preprocessed_groups)\n",
    "try_ml_strategies.try_different_strategies(group_validation = True)"
   ]
  },
  {
   "source": [
    "### Detailed level-of-stress Classification"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_label_ground_truth = np.array([value[0] for value in preprocessed_ground_truth])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = statistic_features\n",
    "y = multi_label_ground_truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Try Logistic Regression...\n",
      "Groups: [['E', 'C', 'D'], ['J', 'K', 'I', 'A'], ['H', 'B', 'G', 'F']]\n",
      "Mean accuracy of train set: 0.45637704908806537\n",
      "Mean accuracy of test set: 0.3799621511280921\n",
      "--------------------------------------\n",
      "Try Random Forests...\n",
      "Groups: [['E', 'C', 'D'], ['J', 'K', 'I', 'A'], ['H', 'B', 'G', 'F']]\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.35998139947099794\n",
      "26 features remain\n",
      "------After ensemble feature selection------\n",
      "Groups: [['E', 'C', 'D'], ['J', 'K', 'I', 'A'], ['H', 'B', 'G', 'F']]\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.3774732363266471\n",
      "--------------------------------------\n",
      "Try Extra Trees Classifier...\n",
      "Groups: [['E', 'C', 'D'], ['J', 'K', 'I', 'A'], ['H', 'B', 'G', 'F']]\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.3757604921731676\n",
      "29 features remain\n",
      "------After ensemble feature selection------\n",
      "Groups: [['E', 'C', 'D'], ['J', 'K', 'I', 'A'], ['H', 'B', 'G', 'F']]\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.3793000370770085\n",
      "--------------------------------------\n",
      "Try SVM Classifier...\n",
      "Groups: [['E', 'C', 'D'], ['J', 'K', 'I', 'A'], ['H', 'B', 'G', 'F']]\n",
      "Mean accuracy of train set: 0.9782681264247236\n",
      "Mean accuracy of test set: 0.4160016236697417\n",
      "--------------------------------------\n",
      "Try MLPClassifier...\n",
      "Groups: [['E', 'C', 'D'], ['J', 'K', 'I', 'A'], ['H', 'B', 'G', 'F']]\n",
      "Mean accuracy of train set: 0.5195234463576505\n",
      "Mean accuracy of test set: 0.3433200049068457\n",
      "--------------------------------------\n",
      "Try 10-nearest-neighbors...\n",
      "Groups: [['E', 'C', 'D'], ['J', 'K', 'I', 'A'], ['H', 'B', 'G', 'F']]\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.3241393723372436\n",
      "--------------------------------------\n",
      "Try decision trees...\n",
      "Groups: [['E', 'C', 'D'], ['J', 'K', 'I', 'A'], ['H', 'B', 'G', 'F']]\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.3045586802238955\n",
      "--------------------------------------\n",
      "Try XGBoostClassifier...\n",
      "Groups: [['E', 'C', 'D'], ['J', 'K', 'I', 'A'], ['H', 'B', 'G', 'F']]\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.35054743720684695\n",
      "--------------------------------------\n",
      "Try Linear Discriminate Analysis...\n",
      "Groups: [['E', 'C', 'D'], ['J', 'K', 'I', 'A'], ['H', 'B', 'G', 'F']]\n",
      "Mean accuracy of train set: 0.42579575067984815\n",
      "Mean accuracy of test set: 0.24715995627945317\n"
     ]
    }
   ],
   "source": [
    "try_ml_strategies = TryMLClassifierStrategy(X, y, groups=preprocessed_groups, multiclass=True)\n",
    "try_ml_strategies.try_different_strategies(group_validation = True)"
   ]
  },
  {
   "source": [
    "## Person-specific stress detection model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Binary classification"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare personal-specific stress detection model\n",
    "person_specific_dataset = defaultdict(dict)\n",
    "person_specific_ground_truth = defaultdict(dict)\n",
    "for participant_id, data in single_signal_data.items():\n",
    "    person_specific_data, person_specific_gt = dataset_loader.prepare_person_specific_dataset(data, ground_truth)\n",
    "    person_specific_dataset[participant_id] = person_specific_data\n",
    "    person_specific_ground_truth[participant_id] = person_specific_gt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Processing A\n",
      "Try Logistic Regression...\n",
      "Mean accuracy of train set: 0.7416666666666666\n",
      "Mean accuracy of test set: 0.4833333333333334\n",
      "11 features remain\n",
      "------After recursive feature elimination------\n",
      "Mean accuracy of train set: 0.7166666666666668\n",
      "Mean accuracy of test set: 0.6\n",
      "--------------------------------------\n",
      "Try Random Forests...\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.6166666666666667\n",
      "15 features remain\n",
      "------After ensemble feature selection------\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.6666666666666666\n",
      "--------------------------------------\n",
      "Try Extra Trees Classifier...\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.6833333333333332\n",
      "19 features remain\n",
      "------After ensemble feature selection------\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.7333333333333334\n",
      "--------------------------------------\n",
      "Try SVM Classifier...\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.6166666666666667\n",
      "--------------------------------------\n",
      "Try MLPClassifier...\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.6\n",
      "--------------------------------------\n",
      "Try 10-nearest-neighbors...\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.65\n",
      "--------------------------------------\n",
      "Try decision trees...\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.43333333333333335\n",
      "--------------------------------------\n",
      "Try XGBoostClassifier...\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.5\n",
      "--------------------------------------\n",
      "Try Linear Discriminate Analysis...\n",
      "Mean accuracy of train set: 0.9916666666666667\n",
      "Mean accuracy of test set: 0.5166666666666666\n",
      "*****************************************\n",
      "Processing B\n",
      "Try Logistic Regression...\n",
      "Mean accuracy of train set: 0.7637637637637638\n",
      "Mean accuracy of test set: 0.5984405458089669\n",
      "1 features remain\n",
      "------After recursive feature elimination------\n",
      "Mean accuracy of train set: 0.6909409409409409\n",
      "Mean accuracy of test set: 0.6910331384015594\n",
      "--------------------------------------\n",
      "Try Random Forests...\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.5984405458089669\n",
      "15 features remain\n",
      "------After ensemble feature selection------\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.6345029239766081\n",
      "--------------------------------------\n",
      "Try Extra Trees Classifier...\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.5984405458089669\n",
      "22 features remain\n",
      "------After ensemble feature selection------\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.6539961013645225\n",
      "--------------------------------------\n",
      "Try SVM Classifier...\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.6910331384015594\n",
      "--------------------------------------\n",
      "Try MLPClassifier...\n",
      "Mean accuracy of train set: 0.9456956956956958\n",
      "Mean accuracy of test set: 0.5643274853801169\n",
      "--------------------------------------\n",
      "Try 10-nearest-neighbors...\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.6189083820662767\n",
      "--------------------------------------\n",
      "Try decision trees...\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.4922027290448343\n",
      "--------------------------------------\n",
      "Try XGBoostClassifier...\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.5789473684210525\n",
      "--------------------------------------\n",
      "Try Linear Discriminate Analysis...\n",
      "Mean accuracy of train set: 0.990990990990991\n",
      "Mean accuracy of test set: 0.5818713450292398\n",
      "*****************************************\n",
      "Processing C\n",
      "Processing D\n",
      "Try Logistic Regression...\n",
      "Mean accuracy of train set: 0.7890365448504983\n",
      "Mean accuracy of test set: 0.6875901875901875\n",
      "34 features remain\n",
      "------After recursive feature elimination------\n",
      "Mean accuracy of train set: 0.7967884828349945\n",
      "Mean accuracy of test set: 0.6717171717171716\n",
      "--------------------------------------\n",
      "Try Random Forests...\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.577922077922078\n",
      "19 features remain\n",
      "------After ensemble feature selection------\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.5937950937950938\n",
      "--------------------------------------\n",
      "Try Extra Trees Classifier...\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.6089466089466089\n",
      "21 features remain\n",
      "------After ensemble feature selection------\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.6255411255411255\n",
      "--------------------------------------\n",
      "Try SVM Classifier...\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.577922077922078\n",
      "--------------------------------------\n",
      "Try MLPClassifier...\n",
      "Mean accuracy of train set: 0.9376153562200074\n",
      "Mean accuracy of test set: 0.6883116883116882\n",
      "--------------------------------------\n",
      "Try 10-nearest-neighbors...\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.63997113997114\n",
      "--------------------------------------\n",
      "Try decision trees...\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.562049062049062\n",
      "--------------------------------------\n",
      "Try XGBoostClassifier...\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.6096681096681097\n",
      "--------------------------------------\n",
      "Try Linear Discriminate Analysis...\n",
      "Mean accuracy of train set: 0.8043558508674787\n",
      "Mean accuracy of test set: 0.611111111111111\n",
      "*****************************************\n",
      "Processing E\n",
      "Try Logistic Regression...\n",
      "Mean accuracy of train set: 0.9509803921568628\n",
      "Mean accuracy of test set: 0.8039215686274511\n",
      "3 features remain\n",
      "------After recursive feature elimination------\n",
      "Mean accuracy of train set: 0.9117647058823529\n",
      "Mean accuracy of test set: 0.8627450980392157\n",
      "--------------------------------------\n",
      "Try Random Forests...\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.9019607843137255\n",
      "8 features remain\n",
      "------After ensemble feature selection------\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.8823529411764706\n",
      "--------------------------------------\n",
      "Try Extra Trees Classifier...\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.8431372549019608\n",
      "9 features remain\n",
      "------After ensemble feature selection------\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.8627450980392156\n",
      "--------------------------------------\n",
      "Try SVM Classifier...\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.607843137254902\n",
      "--------------------------------------\n",
      "Try MLPClassifier...\n",
      "Mean accuracy of train set: 0.9411764705882352\n",
      "Mean accuracy of test set: 0.823529411764706\n",
      "--------------------------------------\n",
      "Try 10-nearest-neighbors...\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.7647058823529412\n",
      "--------------------------------------\n",
      "Try decision trees...\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.7843137254901961\n",
      "--------------------------------------\n",
      "Try XGBoostClassifier...\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.823529411764706\n",
      "--------------------------------------\n",
      "Try Linear Discriminate Analysis...\n",
      "Mean accuracy of train set: 0.9803921568627452\n",
      "Mean accuracy of test set: 0.6862745098039215\n",
      "*****************************************\n",
      "Processing F\n",
      "Try Logistic Regression...\n",
      "Mean accuracy of train set: 0.9493589743589744\n",
      "Mean accuracy of test set: 0.8307017543859648\n",
      "7 features remain\n",
      "------After recursive feature elimination------\n",
      "Mean accuracy of train set: 0.9322649572649574\n",
      "Mean accuracy of test set: 0.8315789473684211\n",
      "--------------------------------------\n",
      "Try Random Forests...\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.7631578947368421\n",
      "12 features remain\n",
      "------After ensemble feature selection------\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.8473684210526317\n",
      "--------------------------------------\n",
      "Try Extra Trees Classifier...\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.8140350877192982\n",
      "13 features remain\n",
      "------After ensemble feature selection------\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.8298245614035088\n",
      "--------------------------------------\n",
      "Try SVM Classifier...\n",
      "Mean accuracy of train set: 0.9747863247863249\n",
      "Mean accuracy of test set: 0.8140350877192982\n",
      "--------------------------------------\n",
      "Try MLPClassifier...\n",
      "Mean accuracy of train set: 0.8649572649572649\n",
      "Mean accuracy of test set: 0.712280701754386\n",
      "--------------------------------------\n",
      "Try 10-nearest-neighbors...\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.7298245614035087\n",
      "--------------------------------------\n",
      "Try decision trees...\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.6271929824561403\n",
      "--------------------------------------\n",
      "Try XGBoostClassifier...\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.812280701754386\n",
      "--------------------------------------\n",
      "Try Linear Discriminate Analysis...\n",
      "Mean accuracy of train set: 0.9743589743589743\n",
      "Mean accuracy of test set: 0.5771929824561404\n",
      "*****************************************\n",
      "Processing G\n",
      "Processing H\n",
      "Processing I\n",
      "Try Logistic Regression...\n",
      "Mean accuracy of train set: 0.92296918767507\n",
      "Mean accuracy of test set: 0.8660130718954248\n",
      "17 features remain\n",
      "------After recursive feature elimination------\n",
      "Mean accuracy of train set: 0.92296918767507\n",
      "Mean accuracy of test set: 0.8834422657952069\n",
      "--------------------------------------\n",
      "Try Random Forests...\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.8660130718954249\n",
      "15 features remain\n",
      "------After ensemble feature selection------\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.8464052287581699\n",
      "--------------------------------------\n",
      "Try Extra Trees Classifier...\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.8464052287581699\n",
      "18 features remain\n",
      "------After ensemble feature selection------\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.8464052287581699\n",
      "--------------------------------------\n",
      "Try SVM Classifier...\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.8464052287581699\n",
      "--------------------------------------\n",
      "Try MLPClassifier...\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.7712418300653594\n",
      "--------------------------------------\n",
      "Try 10-nearest-neighbors...\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.8464052287581699\n",
      "--------------------------------------\n",
      "Try decision trees...\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.6546840958605665\n",
      "--------------------------------------\n",
      "Try XGBoostClassifier...\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.8071895424836603\n",
      "--------------------------------------\n",
      "Try Linear Discriminate Analysis...\n",
      "Mean accuracy of train set: 0.9904761904761905\n",
      "Mean accuracy of test set: 0.5206971677559913\n",
      "*****************************************\n",
      "Processing J\n",
      "Try Logistic Regression...\n",
      "Mean accuracy of train set: 0.8333333333333334\n",
      "Mean accuracy of test set: 0.5555555555555556\n",
      "15 features remain\n",
      "------After recursive feature elimination------\n",
      "Mean accuracy of train set: 0.7777777777777778\n",
      "Mean accuracy of test set: 0.6851851851851851\n",
      "--------------------------------------\n",
      "Try Random Forests...\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.5555555555555555\n",
      "18 features remain\n",
      "------After ensemble feature selection------\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.5925925925925927\n",
      "--------------------------------------\n",
      "Try Extra Trees Classifier...\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.5555555555555555\n",
      "24 features remain\n",
      "------After ensemble feature selection------\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.6111111111111112\n",
      "--------------------------------------\n",
      "Try SVM Classifier...\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.5740740740740741\n",
      "--------------------------------------\n",
      "Try MLPClassifier...\n",
      "Mean accuracy of train set: 0.9907407407407408\n",
      "Mean accuracy of test set: 0.5740740740740741\n",
      "--------------------------------------\n",
      "Try 10-nearest-neighbors...\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.6111111111111112\n",
      "--------------------------------------\n",
      "Try decision trees...\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.48148148148148145\n",
      "--------------------------------------\n",
      "Try XGBoostClassifier...\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.5185185185185185\n",
      "--------------------------------------\n",
      "Try Linear Discriminate Analysis...\n",
      "Mean accuracy of train set: 0.6759259259259259\n",
      "Mean accuracy of test set: 0.4259259259259259\n",
      "*****************************************\n",
      "Processing K\n"
     ]
    }
   ],
   "source": [
    "for participant_id, data in person_specific_dataset.items():\n",
    "    print(f\"Processing {participant_id}\")\n",
    "    person_specific_gt = np.array([0 if value[0] < 2 else 1 for value in person_specific_ground_truth[participant_id]])\n",
    "    if len(list(set(person_specific_gt))) < 2: # If the data contains non-stress value, then continue\n",
    "        continue\n",
    "    person_specific_data, person_specific_gt = dataset_loader.divide_person_specific_data_into_intervals(data, person_specific_gt, num_samples=60)\n",
    "    preprocessed_data, preprocessed_ground_truth, _ = preprocess_data(person_specific_data, person_specific_gt)\n",
    "    person_specific_statistic_features = extract_features(preprocessed_data)\n",
    "    try_ml_strategies = TryMLClassifierStrategy(person_specific_statistic_features, preprocessed_ground_truth)\n",
    "    try_ml_strategies.try_different_strategies(cross_validation = True)\n",
    "    print(\"*****************************************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Processing A\n0: 0.6363636363636364\n1: 0.36363636363636365\nProcessing B\n0: 0.7272727272727273\n1: 0.2727272727272727\nProcessing C\n0: 1.0\nProcessing D\n0: 0.45454545454545453\n1: 0.5454545454545454\nProcessing E\n0: 0.5454545454545454\n1: 0.45454545454545453\nProcessing F\n0: 0.8181818181818182\n1: 0.18181818181818182\nProcessing G\n0: 1.0\nProcessing H\n0: 1.0\nProcessing I\n0: 0.8181818181818182\n1: 0.18181818181818182\nProcessing J\n0: 0.5454545454545454\n1: 0.45454545454545453\nProcessing K\n0: 1.0\n"
     ]
    }
   ],
   "source": [
    "for participant_id, data in person_specific_dataset.items():\n",
    "    print(f\"Processing {participant_id}\")\n",
    "    person_specific_gt = np.array([0 if value[0] < 2 else 1 for value in person_specific_ground_truth[participant_id]])\n",
    "    dataset_loader.class_percentage_analysis(person_specific_gt)"
   ]
  },
  {
   "source": [
    "### Detailed level-of-stress Classification"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Processing A\n",
      "Try Logistic Regression...\n",
      "Mean accuracy of train set: 0.6833333333333332\n",
      "Mean accuracy of test set: 0.3333333333333333\n",
      "5 features remain\n",
      "------After recursive feature elimination------\n",
      "Mean accuracy of train set: 0.5666666666666668\n",
      "Mean accuracy of test set: 0.4833333333333334\n",
      "--------------------------------------\n",
      "Try Random Forests...\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.4333333333333333\n",
      "18 features remain\n",
      "------After ensemble feature selection------\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.5499999999999999\n",
      "--------------------------------------\n",
      "Try Extra Trees Classifier...\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.4000000000000001\n",
      "19 features remain\n",
      "------After ensemble feature selection------\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.4333333333333333\n",
      "--------------------------------------\n",
      "Try SVM Classifier...\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.43333333333333335\n",
      "--------------------------------------\n",
      "Try MLPClassifier...\n",
      "Mean accuracy of train set: 0.9499999999999998\n",
      "Mean accuracy of test set: 0.4166666666666667\n",
      "--------------------------------------\n",
      "Try 10-nearest-neighbors...\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.5\n",
      "--------------------------------------\n",
      "Try decision trees...\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.4000000000000001\n",
      "--------------------------------------\n",
      "Try XGBoostClassifier...\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.4166666666666667\n",
      "--------------------------------------\n",
      "Try Linear Discriminate Analysis...\n",
      "Mean accuracy of train set: 0.9416666666666668\n",
      "Mean accuracy of test set: 0.3333333333333333\n",
      "*****************************************\n",
      "Processing B\n",
      "Try Logistic Regression...\n",
      "Mean accuracy of train set: 0.6086086086086085\n",
      "Mean accuracy of test set: 0.28947368421052627\n",
      "14 features remain\n",
      "------After recursive feature elimination------\n",
      "Mean accuracy of train set: 0.5905905905905907\n",
      "Mean accuracy of test set: 0.30799220272904476\n",
      "--------------------------------------\n",
      "Try Random Forests...\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.5623781676413255\n",
      "16 features remain\n",
      "------After ensemble feature selection------\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.5448343079922028\n",
      "--------------------------------------\n",
      "Try Extra Trees Classifier...\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.5077972709551657\n",
      "22 features remain\n",
      "------After ensemble feature selection------\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.5077972709551657\n",
      "--------------------------------------\n",
      "Try SVM Classifier...\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.43664717348927873\n",
      "--------------------------------------\n",
      "Try MLPClassifier...\n",
      "Mean accuracy of train set: 0.8818818818818818\n",
      "Mean accuracy of test set: 0.32651072124756336\n",
      "--------------------------------------\n",
      "Try 10-nearest-neighbors...\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.4346978557504873\n",
      "--------------------------------------\n",
      "Try decision trees...\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.5058479532163742\n",
      "--------------------------------------\n",
      "Try XGBoostClassifier...\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.4346978557504873\n",
      "--------------------------------------\n",
      "Try Linear Discriminate Analysis...\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.1627680311890838\n",
      "*****************************************\n",
      "Processing C\n",
      "Try Logistic Regression...\n",
      "Mean accuracy of train set: 0.7592592592592592\n",
      "Mean accuracy of test set: 0.5740740740740741\n",
      "1 features remain\n",
      "------After recursive feature elimination------\n",
      "Mean accuracy of train set: 0.6666666666666666\n",
      "Mean accuracy of test set: 0.6666666666666666\n",
      "--------------------------------------\n",
      "Try Random Forests...\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.6111111111111112\n",
      "18 features remain\n",
      "------After ensemble feature selection------\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.6296296296296297\n",
      "--------------------------------------\n",
      "Try Extra Trees Classifier...\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.6296296296296297\n",
      "24 features remain\n",
      "------After ensemble feature selection------\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.5925925925925927\n",
      "--------------------------------------\n",
      "Try SVM Classifier...\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.6666666666666666\n",
      "--------------------------------------\n",
      "Try MLPClassifier...\n",
      "Mean accuracy of train set: 0.9629629629629629\n",
      "Mean accuracy of test set: 0.46296296296296297\n",
      "--------------------------------------\n",
      "Try 10-nearest-neighbors...\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.5555555555555555\n",
      "--------------------------------------\n",
      "Try decision trees...\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.5555555555555555\n",
      "--------------------------------------\n",
      "Try XGBoostClassifier...\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.5\n",
      "--------------------------------------\n",
      "Try Linear Discriminate Analysis...\n",
      "Mean accuracy of train set: 0.888888888888889\n",
      "Mean accuracy of test set: 0.5185185185185185\n",
      "*****************************************\n",
      "Processing D\n",
      "Try Logistic Regression...\n",
      "Mean accuracy of train set: 0.5932078257659653\n",
      "Mean accuracy of test set: 0.4365079365079365\n",
      "1 features remain\n",
      "------After recursive feature elimination------\n",
      "Mean accuracy of train set: 0.5\n",
      "Mean accuracy of test set: 0.5\n",
      "--------------------------------------\n",
      "Try Random Forests...\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.43650793650793646\n",
      "19 features remain\n",
      "------After ensemble feature selection------\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.5151515151515151\n",
      "--------------------------------------\n",
      "Try Extra Trees Classifier...\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.5144300144300145\n",
      "22 features remain\n",
      "------After ensemble feature selection------\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.48412698412698413\n",
      "--------------------------------------\n",
      "Try SVM Classifier...\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.5\n",
      "--------------------------------------\n",
      "Try MLPClassifier...\n",
      "Mean accuracy of train set: 0.7471391657438168\n",
      "Mean accuracy of test set: 0.3759018759018759\n",
      "--------------------------------------\n",
      "Try 10-nearest-neighbors...\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.5324675324675324\n",
      "--------------------------------------\n",
      "Try decision trees...\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.2950937950937951\n",
      "--------------------------------------\n",
      "Try XGBoostClassifier...\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.39033189033189036\n",
      "--------------------------------------\n",
      "Try Linear Discriminate Analysis...\n",
      "Mean accuracy of train set: 0.819859726836471\n",
      "Mean accuracy of test set: 0.28210678210678214\n",
      "*****************************************\n",
      "Processing E\n",
      "Try Logistic Regression...\n",
      "Mean accuracy of train set: 0.7647058823529411\n",
      "Mean accuracy of test set: 0.5294117647058824\n",
      "5 features remain\n",
      "------After recursive feature elimination------\n",
      "Mean accuracy of train set: 0.6568627450980392\n",
      "Mean accuracy of test set: 0.5098039215686274\n",
      "--------------------------------------\n",
      "Try Random Forests...\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.45098039215686275\n",
      "15 features remain\n",
      "------After ensemble feature selection------\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.4313725490196078\n",
      "--------------------------------------\n",
      "Try Extra Trees Classifier...\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.411764705882353\n",
      "15 features remain\n",
      "------After ensemble feature selection------\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.4901960784313726\n",
      "--------------------------------------\n",
      "Try SVM Classifier...\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.29411764705882354\n",
      "--------------------------------------\n",
      "Try MLPClassifier...\n",
      "Mean accuracy of train set: 0.9705882352941176\n",
      "Mean accuracy of test set: 0.5294117647058824\n",
      "--------------------------------------\n",
      "Try 10-nearest-neighbors...\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.45098039215686275\n",
      "--------------------------------------\n",
      "Try decision trees...\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.4705882352941176\n",
      "--------------------------------------\n",
      "Try XGBoostClassifier...\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.411764705882353\n",
      "--------------------------------------\n",
      "Try Linear Discriminate Analysis...\n",
      "Mean accuracy of train set: 0.872549019607843\n",
      "Mean accuracy of test set: 0.1568627450980392\n",
      "*****************************************\n",
      "Processing F\n",
      "Try Logistic Regression...\n",
      "Mean accuracy of train set: 0.644017094017094\n",
      "Mean accuracy of test set: 0.3412280701754386\n",
      "1 features remain\n",
      "------After recursive feature elimination------\n",
      "Mean accuracy of train set: 0.4743589743589744\n",
      "Mean accuracy of test set: 0.4745614035087719\n",
      "--------------------------------------\n",
      "Try Random Forests...\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.35701754385964907\n",
      "19 features remain\n",
      "------After ensemble feature selection------\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.4245614035087719\n",
      "--------------------------------------\n",
      "Try Extra Trees Classifier...\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.3394736842105263\n",
      "22 features remain\n",
      "------After ensemble feature selection------\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.3552631578947369\n",
      "--------------------------------------\n",
      "Try SVM Classifier...\n",
      "Mean accuracy of train set: 0.9745726495726496\n",
      "Mean accuracy of test set: 0.4412280701754386\n",
      "--------------------------------------\n",
      "Try MLPClassifier...\n",
      "Mean accuracy of train set: 0.7784188034188034\n",
      "Mean accuracy of test set: 0.3412280701754386\n",
      "--------------------------------------\n",
      "Try 10-nearest-neighbors...\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.25438596491228066\n",
      "--------------------------------------\n",
      "Try decision trees...\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.3736842105263158\n",
      "--------------------------------------\n",
      "Try XGBoostClassifier...\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.33771929824561403\n",
      "--------------------------------------\n",
      "Try Linear Discriminate Analysis...\n",
      "Mean accuracy of train set: 0.982905982905983\n",
      "Mean accuracy of test set: 0.38947368421052636\n",
      "*****************************************\n",
      "Processing G\n",
      "Try Logistic Regression...\n",
      "Mean accuracy of train set: 0.7397759103641457\n",
      "Mean accuracy of test set: 0.5381263616557734\n",
      "1 features remain\n",
      "------After recursive feature elimination------\n",
      "Mean accuracy of train set: 0.653781512605042\n",
      "Mean accuracy of test set: 0.5958605664488017\n",
      "--------------------------------------\n",
      "Try Random Forests...\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.5958605664488018\n",
      "15 features remain\n",
      "------After ensemble feature selection------\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.596949891067538\n",
      "--------------------------------------\n",
      "Try Extra Trees Classifier...\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.5577342047930284\n",
      "19 features remain\n",
      "------After ensemble feature selection------\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.6928104575163397\n",
      "--------------------------------------\n",
      "Try SVM Classifier...\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.6350762527233115\n",
      "--------------------------------------\n",
      "Try MLPClassifier...\n",
      "Mean accuracy of train set: 0.9711484593837535\n",
      "Mean accuracy of test set: 0.480392156862745\n",
      "--------------------------------------\n",
      "Try 10-nearest-neighbors...\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.5206971677559914\n",
      "--------------------------------------\n",
      "Try decision trees...\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.5762527233115469\n",
      "--------------------------------------\n",
      "Try XGBoostClassifier...\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.5773420479302832\n",
      "--------------------------------------\n",
      "Try Linear Discriminate Analysis...\n",
      "Mean accuracy of train set: 0.8823529411764706\n",
      "Mean accuracy of test set: 0.47930283224400866\n",
      "*****************************************\n",
      "Processing H\n",
      "Try Logistic Regression...\n",
      "Mean accuracy of train set: 0.7706093189964158\n",
      "Mean accuracy of test set: 0.49861111111111106\n",
      "12 features remain\n",
      "------After recursive feature elimination------\n",
      "Mean accuracy of train set: 0.6842293906810036\n",
      "Mean accuracy of test set: 0.5194444444444445\n",
      "--------------------------------------\n",
      "Try Random Forests...\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.3902777777777778\n",
      "17 features remain\n",
      "------After ensemble feature selection------\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.5013888888888889\n",
      "--------------------------------------\n",
      "Try Extra Trees Classifier...\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.4777777777777777\n",
      "18 features remain\n",
      "------After ensemble feature selection------\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.5416666666666666\n",
      "--------------------------------------\n",
      "Try SVM Classifier...\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.5\n",
      "--------------------------------------\n",
      "Try MLPClassifier...\n",
      "Mean accuracy of train set: 0.9781362007168459\n",
      "Mean accuracy of test set: 0.4124999999999999\n",
      "--------------------------------------\n",
      "Try 10-nearest-neighbors...\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.37083333333333335\n",
      "--------------------------------------\n",
      "Try decision trees...\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.4583333333333333\n",
      "--------------------------------------\n",
      "Try XGBoostClassifier...\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.4777777777777778\n",
      "--------------------------------------\n",
      "Try Linear Discriminate Analysis...\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.5416666666666666\n",
      "*****************************************\n",
      "Processing I\n",
      "Try Logistic Regression...\n",
      "Mean accuracy of train set: 0.6918767507002802\n",
      "Mean accuracy of test set: 0.5370370370370371\n",
      "26 features remain\n",
      "------After recursive feature elimination------\n",
      "Mean accuracy of train set: 0.6918767507002802\n",
      "Mean accuracy of test set: 0.5392156862745098\n",
      "--------------------------------------\n",
      "Try Random Forests...\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.4030501089324619\n",
      "18 features remain\n",
      "------After ensemble feature selection------\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.46078431372549017\n",
      "--------------------------------------\n",
      "Try Extra Trees Classifier...\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.4041394335511983\n",
      "23 features remain\n",
      "------After ensemble feature selection------\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.4041394335511983\n",
      "--------------------------------------\n",
      "Try SVM Classifier...\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.5392156862745098\n",
      "--------------------------------------\n",
      "Try MLPClassifier...\n",
      "Mean accuracy of train set: 0.9613445378151261\n",
      "Mean accuracy of test set: 0.5196078431372549\n",
      "--------------------------------------\n",
      "Try 10-nearest-neighbors...\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.40196078431372556\n",
      "--------------------------------------\n",
      "Try decision trees...\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.3278867102396514\n",
      "--------------------------------------\n",
      "Try XGBoostClassifier...\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.36710239651416127\n",
      "--------------------------------------\n",
      "Try Linear Discriminate Analysis...\n",
      "Mean accuracy of train set: 0.892436974789916\n",
      "Mean accuracy of test set: 0.480392156862745\n",
      "*****************************************\n",
      "Processing J\n",
      "Try Logistic Regression...\n",
      "Mean accuracy of train set: 0.7222222222222222\n",
      "Mean accuracy of test set: 0.4259259259259259\n",
      "26 features remain\n",
      "------After recursive feature elimination------\n",
      "Mean accuracy of train set: 0.7314814814814814\n",
      "Mean accuracy of test set: 0.4259259259259259\n",
      "--------------------------------------\n",
      "Try Random Forests...\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.4444444444444444\n",
      "19 features remain\n",
      "------After ensemble feature selection------\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.48148148148148145\n",
      "--------------------------------------\n",
      "Try Extra Trees Classifier...\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.48148148148148145\n",
      "18 features remain\n",
      "------After ensemble feature selection------\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.46296296296296297\n",
      "--------------------------------------\n",
      "Try SVM Classifier...\n",
      "Mean accuracy of train set: 0.9907407407407408\n",
      "Mean accuracy of test set: 0.48148148148148145\n",
      "--------------------------------------\n",
      "Try MLPClassifier...\n",
      "Mean accuracy of train set: 0.9722222222222222\n",
      "Mean accuracy of test set: 0.4444444444444444\n",
      "--------------------------------------\n",
      "Try 10-nearest-neighbors...\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.48148148148148145\n",
      "--------------------------------------\n",
      "Try decision trees...\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.25925925925925924\n",
      "--------------------------------------\n",
      "Try XGBoostClassifier...\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.5370370370370371\n",
      "--------------------------------------\n",
      "Try Linear Discriminate Analysis...\n",
      "Mean accuracy of train set: 0.638888888888889\n",
      "Mean accuracy of test set: 0.2777777777777778\n",
      "*****************************************\n",
      "Processing K\n",
      "Try Logistic Regression...\n",
      "Mean accuracy of train set: 0.9497920380273323\n",
      "Mean accuracy of test set: 0.8394607843137255\n",
      "30 features remain\n",
      "------After recursive feature elimination------\n",
      "Mean accuracy of train set: 0.9497920380273323\n",
      "Mean accuracy of test set: 0.8394607843137255\n",
      "--------------------------------------\n",
      "Try Random Forests...\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.9007352941176471\n",
      "16 features remain\n",
      "------After ensemble feature selection------\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.9007352941176471\n",
      "--------------------------------------\n",
      "Try Extra Trees Classifier...\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.9007352941176471\n",
      "18 features remain\n",
      "------After ensemble feature selection------\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.8799019607843137\n",
      "--------------------------------------\n",
      "Try SVM Classifier...\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.9007352941176471\n",
      "--------------------------------------\n",
      "Try MLPClassifier...\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.8590686274509803\n",
      "--------------------------------------\n",
      "Try 10-nearest-neighbors...\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.8590686274509803\n",
      "--------------------------------------\n",
      "Try decision trees...\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.7781862745098039\n",
      "--------------------------------------\n",
      "Try XGBoostClassifier...\n",
      "Mean accuracy of train set: 1.0\n",
      "Mean accuracy of test set: 0.8590686274509803\n",
      "--------------------------------------\n",
      "Try Linear Discriminate Analysis...\n",
      "Mean accuracy of train set: 0.9901960784313726\n",
      "Mean accuracy of test set: 0.5049019607843137\n",
      "*****************************************\n"
     ]
    }
   ],
   "source": [
    "for participant_id, data in person_specific_dataset.items():\n",
    "    print(f\"Processing {participant_id}\")\n",
    "    person_specific_gt = np.array([value[0] for value in person_specific_ground_truth[participant_id]])\n",
    "    if len(list(set(person_specific_gt))) < 2: # If the data contains non-stress value, then continue\n",
    "        continue\n",
    "    person_specific_data, person_specific_gt = dataset_loader.divide_person_specific_data_into_intervals(data, person_specific_gt, num_samples=60)\n",
    "    preprocessed_data, preprocessed_ground_truth, _ = preprocess_data(person_specific_data, person_specific_gt)\n",
    "    person_specific_statistic_features = extract_features(preprocessed_data)\n",
    "    try_ml_strategies = TryMLClassifierStrategy(person_specific_statistic_features, preprocessed_ground_truth)\n",
    "    try_ml_strategies.try_different_strategies(cross_validation = True)\n",
    "    print(\"*****************************************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Processing A\n0: 0.45454545454545453\n1: 0.18181818181818182\n2: 0.36363636363636365\nProcessing B\n0: 0.45454545454545453\n1: 0.2727272727272727\n2: 0.18181818181818182\n3: 0.09090909090909091\nProcessing C\n0: 0.6\n1: 0.4\nProcessing D\n0: 0.18181818181818182\n1: 0.2727272727272727\n2: 0.45454545454545453\n3: 0.09090909090909091\nProcessing E\n0: 0.2727272727272727\n1: 0.2727272727272727\n3: 0.2727272727272727\n2: 0.18181818181818182\nProcessing F\n0: 0.45454545454545453\n1: 0.36363636363636365\n3: 0.09090909090909091\n2: 0.09090909090909091\nProcessing G\n0: 0.36363636363636365\n1: 0.6363636363636364\nProcessing H\n0: 0.5\n1: 0.5\nProcessing I\n0: 0.2727272727272727\n1: 0.5454545454545454\n2: 0.18181818181818182\nProcessing J\n0: 0.45454545454545453\n1: 0.09090909090909091\n2: 0.45454545454545453\nProcessing K\n0: 0.9090909090909091\n1: 0.09090909090909091\n"
     ]
    }
   ],
   "source": [
    "for participant_id, data in person_specific_dataset.items():\n",
    "    print(f\"Processing {participant_id}\")\n",
    "    person_specific_gt = np.array([value[0] for value in person_specific_ground_truth[participant_id]])\n",
    "    dataset_loader.class_percentage_analysis(person_specific_gt)"
   ]
  }
 ]
}