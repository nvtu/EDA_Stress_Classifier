{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import neurokit2 as nk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import configparser\n",
    "import os\n",
    "import os.path as osp\n",
    "import pickle\n",
    "from eda_signal_processing import *\n",
    "from typing import Dict, List\n",
    "from tqdm import tqdm\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load eda signal from datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize file paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset_folder_path(dataset_name: str) -> str:\r\n",
    "    # Read dataset path from config.ini file\r\n",
    "    config_path = osp.join(osp.dirname(os.getcwd()), 'config.ini')\r\n",
    "    parser = configparser.ConfigParser()\r\n",
    "    parser.read(config_path)\r\n",
    "    dataset_folder_path = None\r\n",
    "    if dataset_name == 'AffectiveROAD':\r\n",
    "        dataset_folder_path = parser['DATA_PATH']['affectiveROAD_dataset_path']\r\n",
    "    elif dataset_name in ['WESAD_CHEST', 'WESAD_WRIST', 'RESAMPLED_WESAD_CHEST']:\r\n",
    "        dataset_folder_path = parser['DATA_PATH']['wesad_dataset_path']\r\n",
    "    elif dataset_name == 'DCU_NVT_EXP1':\r\n",
    "        dataset_folder_path = parser['DATA_PATH']['dcu_nvt_dataset_path']\r\n",
    "    return dataset_folder_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_raw_dataset(dataset_name: str):\r\n",
    "    dataset = None\r\n",
    "    # Initialize dataset folder paths\r\n",
    "    dataset_folder_path = get_dataset_folder_path(dataset_name)\r\n",
    "    if dataset_name == 'AffectiveROAD':\r\n",
    "        # Initialize dataset paths\r\n",
    "        affectiveROAD_dataset_file_path = osp.join(dataset_folder_path, 'affectiveROAD_dataset.pkl')\r\n",
    "        dataset = pickle.load(open(affectiveROAD_dataset_file_path, 'rb')) # Load affectiveROAD dataset -> sampling_rate = 4 Hz\r\n",
    "    elif dataset_name == 'WESAD_CHEST':\r\n",
    "        # Initialize dataset paths\r\n",
    "        wesad_chest_file_path = osp.join(dataset_folder_path, 'wesad_chest_dataset.pkl')\r\n",
    "        dataset = pickle.load(open(wesad_chest_file_path, 'rb')) # Load WESAD_CHEST dataset -> sampling_rate = 700 Hz\r\n",
    "    elif dataset_name == 'RESAMPLED_WESAD_CHEST':\r\n",
    "        # Initialize dataset paths\r\n",
    "        resampled_wesad_file_path = osp.join(dataset_folder_path, 'wesad_chest_resampling_dataset.pkl')\r\n",
    "        dataset = pickle.load(open(resampled_wesad_file_path, 'rb')) # Load RESAMPLED_WESAD_CHEST dataset -> sampling_rate = 4 Hz\r\n",
    "    elif dataset_name == 'WESAD_WRIST':\r\n",
    "        # Initialize dataset paths\r\n",
    "        wesad_wrist_file_path = osp.join(dataset_folder_path, 'wesad_wrist_dataset.pkl')\r\n",
    "        dataset = pickle.load(open(wesad_wrist_file_path, 'rb')) # Load WESAD_WRIST dataset -> sampling_rate = 4 Hz\r\n",
    "    elif dataset_name == 'DCU_NVT_EXP1':\r\n",
    "        # Initialize dataset paths\r\n",
    "        dcu_nvt_file_path = osp.join(dataset_folder_path, 'DCU_NVT_EXP1_dataset.pkl')\r\n",
    "        dataset = pickle.load(open(dcu_nvt_file_path, 'rb')) # Load DCU_NVT_EXP1 dataset -> sampling_rate = 5 Hz\r\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Uncomment the dataset that you wanna load -- # \n",
    "dataset_name = 'AffectiveROAD'\n",
    "dataset_name = 'WESAD_CHEST'\n",
    "dataset_name = 'WESAD_WRIST'\n",
    "# dataset_name = 'RESAMPLED_WESAD_CHEST'\n",
    "dataset_name = 'DCU_NVT_EXP1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_raw_dataset(dataset_name) # Load dataset\n",
    "eda = dataset['eda'] # Get raw EDA signal\n",
    "ground_truth = dataset['ground_truth'] # Get its corresponding ground-truth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract statistical features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Declare functions to process and extract statistical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract statistical features from the EDA signal with a current WINDOW_SIZE and WINDOW_SHIFT\r\n",
    "def extract_stats_features(eda: Dict[str, Dict[str, List[float]]], window_size: int, window_shift: int, sampling_rate: int) -> np.array:\r\n",
    "    \"\"\" This function extract stats feature corresponding to left-side of the current eda signal with length equals to window_size \"\"\" \r\n",
    "    # window_size: unit -> seconds - the length of signal which is cut to extract statistical feature equals to 60 seconds\r\n",
    "    # window_shift: unit -> seconds - the step of the sliding window\r\n",
    "    # sampling_rate: unit -> Hz - the number of recorded points per second\r\n",
    "    stats_features = []\r\n",
    "    for user_id, data in tqdm(eda.items()):\r\n",
    "        for task_id, eda_signal in data.items():\r\n",
    "            len_eda_signal = len(eda_signal)\r\n",
    "            step = window_shift * sampling_rate # The true step to slide along the time axis of the signal\r\n",
    "            first_iter = window_size * sampling_rate # The true index of the signal at a time-point \r\n",
    "            for current_iter in range(first_iter, len_eda_signal, step): # current_iter is \"second_iter\"\r\n",
    "                previous_iter = current_iter - first_iter\r\n",
    "                signal = eda_signal[previous_iter:current_iter]\r\n",
    "                eda_features = extract_eda_features(signal, sampling_rate) # Extract SCR, SCL, Onset, Offset, Peaks, etc.\r\n",
    "                eda_stats_features = extract_statistics_eda_features(eda_features) # Extract statistical features from extracted EDA features\r\n",
    "                stats_features.append(eda_stats_features)\r\n",
    "    stats_features = np.array(stats_features) # Transform to numpy array format\r\n",
    "    return stats_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_ground_truth(ground_truth: Dict[str, Dict[str, List[int]]], window_size: int, window_shift: int, sampling_rate: int) -> np.array: \n",
    "    \"\"\" This function should be call after the function extract_stats_features is called.\n",
    "        The iterative order of this function is the same as extract_stats_features function to maintain the integrity of the dataset.\n",
    "    \"\"\"\n",
    "    # window_size: unit -> seconds - the length of signal which is cut to extract statistical feature equals to 60 seconds\n",
    "    # window_shift: unit -> seconds - the step of the sliding window\n",
    "    # sampling_rate: unit -> Hz - the number of recorded points per second\n",
    "    gt = []\n",
    "    for user_id, data in tqdm(ground_truth.items()):\n",
    "        for task_id, _ground_truth in data.items():\n",
    "            len_ground_truth = len(_ground_truth)\n",
    "            start_index = window_size * sampling_rate # The true index of the signal at a time-point\n",
    "            step = window_shift * sampling_rate\n",
    "            gt += [_ground_truth[index] for index in range(start_index, len_ground_truth, step)] # Append the flatten array \n",
    "    gt = np.array(gt) # Transform to numpy array format\n",
    "    return gt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data_groups_from_ground_truth(ground_truth: Dict[str, Dict[str, List[int]]], window_size: int, window_shift: int, sampling_rate: int) -> np.array:\n",
    "    \"\"\" This function should be call after the function extract_stats_features is called.\n",
    "        The iterative order of this function is the same as extract_stats_features and map_ground_truth functions to maintain the integrity of the dataset.\n",
    "        Generate user_id label for each statistical features using ground-truth\n",
    "    \"\"\"\n",
    "    # window_size: unit -> seconds - the length of signal which is cut to extract statistical feature equals to 60 seconds\n",
    "    # window_shift: unit -> seconds - the step of the sliding window\n",
    "    # sampling_rate: unit -> Hz - the number of recorded points per second\n",
    "    groups = []\n",
    "    for user_id, data in tqdm(ground_truth.items()):\n",
    "        for task_id, _ground_truth in data.items():\n",
    "            len_ground_truth = len(_ground_truth)\n",
    "            start_index = window_size * sampling_rate\n",
    "            step = window_shift * sampling_rate\n",
    "            groups += [user_id for _ in range(start_index, len_ground_truth, step)]\n",
    "    groups = np.array(groups)\n",
    "    return groups\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sampling_rate(dataset_name: str) -> int:\r\n",
    "    sampling_rate = None\r\n",
    "    if dataset_name in ['AffectiveROAD', 'WESAD_WRIST', 'RESAMPLED_WESAD_CHEST']:\r\n",
    "        sampling_rate = 4\r\n",
    "    elif dataset_name == 'WESAD_CHEST':\r\n",
    "        sampling_rate = 700\r\n",
    "    elif dataset_name == 'DCU_NVT_EXP1':\r\n",
    "        sampling_rate = 5\r\n",
    "    return sampling_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract statistical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "WINDOW_SIZE = 60 # the length of signal which is cut to extract statistical feature equals to 60 seconds\n",
    "WINDOW_SHIFT = 20 # the step of the sliding window \n",
    "SAMPLING_RATE = get_sampling_rate(dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 11/11 [00:37<00:00,  3.36s/it]\n"
     ]
    }
   ],
   "source": [
    "# Extract EDA statistical features \n",
    "eda_stats_features = extract_stats_features(eda, WINDOW_SIZE, WINDOW_SHIFT, SAMPLING_RATE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 11/11 [00:00<00:00, 11013.93it/s]\n"
     ]
    }
   ],
   "source": [
    "# Map ground-truth to the features \n",
    "mapped_ground_truth = map_ground_truth(ground_truth, WINDOW_SIZE, WINDOW_SHIFT, SAMPLING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 11/11 [00:00<00:00, 10992.93it/s]\n"
     ]
    }
   ],
   "source": [
    "# Label the group of the data also\n",
    "groups = generate_data_groups_from_ground_truth(ground_truth, WINDOW_SIZE, WINDOW_SHIFT, SAMPLING_RATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save extracted features and their corresponding ground-truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_folder_path = get_dataset_folder_path(dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the features to files in .npy format\n",
    "feat_output_file_path = osp.join(dataset_folder_path, f'{dataset_name}_stats_feats.npy')\n",
    "np.save(feat_output_file_path, eda_stats_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the ground-truth of the corresponding signal at its corresponding time-point\n",
    "gt_output_file_path = osp.join(dataset_folder_path, f'{dataset_name}_ground_truth.npy')\n",
    "np.save(gt_output_file_path, mapped_ground_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the user_id mapping of the statistical features\n",
    "groups_output_file_path = osp.join(dataset_folder_path, f'{dataset_name}_groups.npy')\n",
    "np.save(groups_output_file_path, groups) "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "820beee9ae6002b7a74b94e11c684a186db5ecded8789d3d7a3f1b5d99becc3a"
  },
  "kernelspec": {
   "name": "python391jvsc74a57bd0820beee9ae6002b7a74b94e11c684a186db5ecded8789d3d7a3f1b5d99becc3a",
   "display_name": "Python 3.9.1 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}