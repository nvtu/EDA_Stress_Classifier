{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "import neurokit2 as nk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import configparser\n",
    "import os\n",
    "import os.path as osp\n",
    "import pickle\n",
    "from bvp_signal_processing import *\n",
    "from typing import Dict, List\n",
    "from tqdm import tqdm\n",
    "import scipy\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load bvp signal from datasets"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Initialize file paths"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "def get_dataset_folder_path(dataset_name: str) -> str:\n",
    "    # Read dataset path from config.ini file\n",
    "    config_path = osp.join(osp.dirname(os.getcwd()), 'config.ini')\n",
    "    parser = configparser.ConfigParser()\n",
    "    parser.read(config_path)\n",
    "    dataset_folder_path = None\n",
    "    if dataset_name == 'AffectiveROAD':\n",
    "        dataset_folder_path = parser['DATA_PATH']['affectiveROAD_dataset_path']\n",
    "    elif dataset_name in ['WESAD_CHEST', 'WESAD_WRIST', 'RESAMPLED_WESAD_CHEST']:\n",
    "        dataset_folder_path = parser['DATA_PATH']['wesad_dataset_path']\n",
    "    elif dataset_name == 'DCU_NVT_EXP1':\n",
    "        dataset_folder_path = parser['DATA_PATH']['dcu_nvt_dataset_path']\n",
    "    return dataset_folder_path"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "def load_raw_dataset(dataset_name: str):\n",
    "    dataset = None\n",
    "    # Initialize dataset folder paths\n",
    "    dataset_folder_path = get_dataset_folder_path(dataset_name)\n",
    "    if dataset_name == 'AffectiveROAD':\n",
    "        # Initialize dataset paths\n",
    "        affectiveROAD_dataset_file_path = osp.join(dataset_folder_path, 'affectiveROAD_dataset.pkl')\n",
    "        dataset = pickle.load(open(affectiveROAD_dataset_file_path, 'rb')) # Load affectiveROAD dataset -> sampling_rate = 4 Hz\n",
    "    elif dataset_name == 'WESAD_CHEST':\n",
    "        # Initialize dataset paths\n",
    "        wesad_chest_file_path = osp.join(dataset_folder_path, 'wesad_chest_dataset.pkl')\n",
    "        dataset = pickle.load(open(wesad_chest_file_path, 'rb')) # Load WESAD_CHEST dataset -> sampling_rate = 700 Hz\n",
    "    elif dataset_name == 'RESAMPLED_WESAD_CHEST':\n",
    "        # Initialize dataset paths\n",
    "        resampled_wesad_file_path = osp.join(dataset_folder_path, 'wesad_chest_resampling_dataset.pkl')\n",
    "        dataset = pickle.load(open(resampled_wesad_file_path, 'rb')) # Load RESAMPLED_WESAD_CHEST dataset -> sampling_rate = 4 Hz\n",
    "    elif dataset_name == 'WESAD_WRIST':\n",
    "        # Initialize dataset paths\n",
    "        wesad_wrist_file_path = osp.join(dataset_folder_path, 'wesad_wrist_dataset.pkl')\n",
    "        dataset = pickle.load(open(wesad_wrist_file_path, 'rb')) # Load WESAD_WRIST dataset -> sampling_rate = 4 Hz\n",
    "    elif dataset_name == 'DCU_NVT_EXP1':\n",
    "        # Initialize dataset paths\n",
    "        dcu_nvt_file_path = osp.join(dataset_folder_path, 'DCU_NVT_EXP1_dataset.pkl')\n",
    "        dataset = pickle.load(open(dcu_nvt_file_path, 'rb')) # Load DCU_NVT_EXP1 dataset -> sampling_rate = 5 Hz\n",
    "    return dataset"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load datasets"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "source": [
    "# -- Uncomment the dataset that you wanna load -- # \n",
    "dataset_name = 'AffectiveROAD'\n",
    "# dataset_name = 'WESAD_CHEST'\n",
    "# dataset_name = 'WESAD_WRIST'\n",
    "# dataset_name = 'RESAMPLED_WESAD_CHEST'\n",
    "# dataset_name = 'DCU_NVT_EXP1'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "source": [
    "dataset = load_raw_dataset(dataset_name) # Load dataset\n",
    "bvp = dataset['bvp'] # Get raw BVP signal\n",
    "ground_truth = dataset['ground_truth'] # Get its corresponding ground-truth"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Extract statistical features"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Declare functions to process and extract statistical features"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "source": [
    "# Extract statistical features from the BVP signal with a current WINDOW_SIZE and WINDOW_SHIFT\n",
    "def extract_stats_features(bvp: Dict[str, Dict[str, List[float]]], window_size: int, window_shift: int, sampling_rate: int) -> np.array:\n",
    "    \"\"\" This function extract stats feature corresponding to left-side of the current bvp signal with length equals to window_size \"\"\" \n",
    "    # window_size: unit -> seconds - the length of signal which is cut to extract statistical feature equals to 60 seconds\n",
    "    # window_shift: unit -> seconds - the step of the sliding window\n",
    "    # sampling_rate: unit -> Hz - the number of recorded points per second\n",
    "    stats_features = []\n",
    "    for user_id, data in tqdm(bvp.items()):\n",
    "        for task_id, bvp_signal in data.items():\n",
    "            len_bvp_signal = len(bvp_signal)\n",
    "            step = window_shift * sampling_rate # The true step to slide along the time axis of the signal\n",
    "            first_iter = window_size * sampling_rate # The true index of the signal at a time-point \n",
    "            for current_iter in range(first_iter, len_bvp_signal, step): # current_iter is \"second_iter\"\n",
    "                previous_iter = current_iter - first_iter\n",
    "                signal = bvp_signal[previous_iter:current_iter]\n",
    "                bvp_stats_features = extract_bvp_features(signal, sampling_rate) # Extract statistical features from extracted BVP features\n",
    "                stats_features.append(bvp_stats_features)\n",
    "    stats_features = np.array(stats_features) # Transform to numpy array format\n",
    "    return stats_features"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "source": [
    "def get_sampling_rate(dataset_name: str) -> int:\n",
    "    sampling_rate = None\n",
    "    if dataset_name in ['AffectiveROAD', 'WESAD_WRIST', 'RESAMPLED_WESAD_CHEST']:\n",
    "        sampling_rate = 64\n",
    "    elif dataset_name == 'WESAD_CHEST':\n",
    "        sampling_rate = 700\n",
    "    elif dataset_name == 'DCU_NVT_EXP1':\n",
    "        sampling_rate = 5\n",
    "    return sampling_rate"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Extract statistical features"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "source": [
    "WINDOW_SIZE = 120 # the length of signal which is cut to extract statistical feature equals to 60 seconds\n",
    "WINDOW_SHIFT = 1 # the step of the sliding window \n",
    "SAMPLING_RATE = get_sampling_rate(dataset_name)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "source": [
    "# Extract BVP statistical features \n",
    "bvp_stats_features = extract_stats_features(bvp, WINDOW_SIZE, WINDOW_SHIFT, SAMPLING_RATE)\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 15/15 [48:50<00:00, 195.39s/it]\n"
     ]
    }
   ],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Save extracted features and their corresponding ground-truth"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "source": [
    "dataset_folder_path = get_dataset_folder_path(dataset_name)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "source": [
    "# Save the features to files in .npy format\n",
    "feat_output_file_path = osp.join(dataset_folder_path, f'{dataset_name}_heart_stats_feats_1.npy')\n",
    "np.save(feat_output_file_path, bvp_stats_features)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "source": [
    "np.any(np.isnan(bvp_stats_features) == True)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 42
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "source": [
    "np.argwhere(np.isnan(bvp_stats_features))"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[20953,    11],\n",
       "       [20953,    13],\n",
       "       [20953,    14],\n",
       "       [20954,    11],\n",
       "       [20954,    13],\n",
       "       [20954,    14],\n",
       "       [20955,    11],\n",
       "       [20955,    13],\n",
       "       [20955,    14],\n",
       "       [20956,    11],\n",
       "       [20956,    13],\n",
       "       [20956,    14],\n",
       "       [20957,    11],\n",
       "       [20957,    13],\n",
       "       [20957,    14]])"
      ]
     },
     "metadata": {},
     "execution_count": 43
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a1d5b9100ccb4936a513a4c2e96581413c43726381ca42ceaddfd68a024f20b1"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.3 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}